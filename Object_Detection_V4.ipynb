{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "pp5I5I5aJkEV"
      ],
      "authorship_tag": "ABX9TyOQwMgfGtyHAI+aiK+Gz5Tm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thegregbeyond/FreeFuse-AI-Calbright-Project/blob/main/Object_Detection_V4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Extract Video Stills"
      ],
      "metadata": {
        "id": "5FmghcqzHyY7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8it6gaWVGPL"
      },
      "outputs": [],
      "source": [
        "# EXTRACT INDIVIDUAL STILLS FROM EACH VIDEO IN A SOURCE FOLDER.\n",
        "# CAN DEFINE STARTING SECOND AND INTERVAL BETWEEN STILLS IN SECONDS.\n",
        "\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "\n",
        "# === Configuration ===\n",
        "INPUT_DIR = Path('/content/drive/MyDrive/FreeFuse_Project/Source_Videos/Alloy Personal Training')\n",
        "OUTPUT_DIR = Path('/content/drive/MyDrive/FreeFuse_Project/Extracted_Stills')\n",
        "CAPTURE_INTERVAL_S = 4      # seconds between captures\n",
        "START_TIME_S = 1            # skip first N seconds of each video\n",
        "VIDEO_EXTS = {'.mp4', '.mov', '.avi'}\n",
        "\n",
        "\n",
        "def mount_drive(mount_point: Path = Path('/content/drive')) -> None:\n",
        "    \"\"\"\n",
        "    Mount Google Drive at the given mount_point if not already mounted.\n",
        "    \"\"\"\n",
        "    if not mount_point.exists() or not any(mount_point.iterdir()):\n",
        "        print(\"Mounting Google Drive…\")\n",
        "        drive.mount(str(mount_point), force_remount=True)\n",
        "        print(\"Drive mounted.\")\n",
        "    else:\n",
        "        print(\"Google Drive already mounted.\")\n",
        "\n",
        "\n",
        "def extract_stills(\n",
        "    input_dir: Path,\n",
        "    output_dir: Path,\n",
        "    interval_s: float,\n",
        "    start_s: float\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Extract frames every `interval_s` seconds from each video in `input_dir`,\n",
        "    skipping the first `start_s` seconds, and save them to `output_dir` with\n",
        "    filenames as <video_stem>_<total_seconds_padded_4d>.jpg.\n",
        "    \"\"\"\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    video_files = [f for f in sorted(input_dir.iterdir()) if f.suffix.lower() in VIDEO_EXTS]\n",
        "\n",
        "    if not video_files:\n",
        "        print(f\"No videos found in {input_dir}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(video_files)} videos in {input_dir}\")\n",
        "    for idx, video_file in enumerate(video_files, start=1):\n",
        "        print(f\"[{idx}/{len(video_files)}] Processing '{video_file.name}'\")\n",
        "        cap = cv2.VideoCapture(str(video_file))\n",
        "        if not cap.isOpened():\n",
        "            print(f\"  ✗ Could not open {video_file.name}, skipping.\")\n",
        "            continue\n",
        "\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
        "        start_frame = int(start_s * fps)\n",
        "        if start_frame > 0:\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
        "            print(f\"  → Skipped first {start_s}s ({start_frame} frames)\")\n",
        "\n",
        "        next_capture = start_s\n",
        "        saved_count = 0\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            current_s = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0\n",
        "            if current_s >= next_capture:\n",
        "                total_sec = int(current_s)\n",
        "                timestamp = f\"{total_sec:04d}\"\n",
        "                filename = f\"{video_file.stem}_{timestamp}.jpg\"\n",
        "                filepath = output_dir / filename\n",
        "                cv2.imwrite(str(filepath), frame)\n",
        "                print(f\"  ✔ Saved {filename}\")\n",
        "                saved_count += 1\n",
        "                next_capture += interval_s\n",
        "\n",
        "        cap.release()\n",
        "        print(f\"  Completed '{video_file.name}', saved {saved_count} frames.\\n\")\n",
        "\n",
        "    print(\"All videos processed.\")\n",
        "\n",
        "\n",
        "def main() -> None:\n",
        "    mount_drive()\n",
        "    extract_stills(INPUT_DIR, OUTPUT_DIR, CAPTURE_INTERVAL_S, START_TIME_S)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Object Detection"
      ],
      "metadata": {
        "id": "a_9DCsIuJdxm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Annotation File Schema:**\n",
        "* frame_id (string): Unique frame identifier (e.g., 'video123_0030').\n",
        "* track_id (string): Ppersistent ID for unique object instance across multiple frames (for future use)\n",
        "* object_id (string): Unique identifier for object within this specific frame (e.g., 'video123_0030_obj1').\n",
        "* timestamp_sec (integer): Time offset in seconds when still was captured.\n",
        "* image_width_px (integer): Width of still image in pixels.\n",
        "* image_height_px (integer): Height of still image in pixels.\n",
        "* machine_id (string): Machine-generated ID for detected object class from knowledge graph (e.g., '/m/0271t').\n",
        "* object_name (string): Detected object label in its canonical form (e.g., 'coffee_mug').\n",
        "* object_category (string): Gigh-level grouping for object (e.g., 'electronics', 'furniture').\n",
        "* x_min (integer): Left coordinate of the bounding box in pixels.\n",
        "* y_min (integer): Top coordinate of the bounding box in pixels.\n",
        "* x_max (integer): Right coordinate of the bounding box in pixels.\n",
        "* y_max (integer): Bottom coordinate of the bounding box in pixels.\n",
        "* segmentation_mask (string): Pixel-wise mask for object, stored as array of polygon coordinates (e.g., '[[[x1,y1],[x2,y2],...]]').\n",
        "* confidence (float): Model's confidence score for initial detection (0.0–1.0).\n",
        "* interaction_score (float): Score (real or mocked) representing object's potential for user engagement (0.0–1.0)."
      ],
      "metadata": {
        "id": "uVKANrBIYOdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATES EXPANDED ANNOTATION FILE BASED ON FASTER R-CNN MODEL.\n",
        "# BASED ON THE OPEN IMAGES V4 MODEL WHICH INCLUDES 600 OBJECT CLASSES.\n",
        "# OBJECT CATEGORY IS POPULATED BASED ON CANONICAL MAPPING OF THOSE CLASSES.\n",
        "# NOTE THAT THIS IS A HEAVY-WEIGHT ALGORITHM AND MAY RUN SLOW.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "import json\n",
        "import random\n",
        "\n",
        "# ─── Configuration ───────────────────────────────────────────────────────────────\n",
        "STILLS_DIR      = Path('/content/drive/MyDrive/FreeFuse_Project/Extracted_Stills')\n",
        "OUTPUT_CSV      = STILLS_DIR / 'final_annotations.csv'\n",
        "MODEL_URL       = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"\n",
        "MAX_OBJECTS     = 8\n",
        "CONF_THRESHOLD  = 0.4\n",
        "\n",
        "# ─── Taxonomy Mapping ───────────────────────────────────────────────────────────\n",
        "# Maps lower-cased object names to high-level categories\n",
        "TAXONOMY_MAP = {\n",
        "    # --- Human & Person ---\n",
        "    'person': 'human_and_person', 'man': 'human_and_person', 'woman': 'human_and_person',\n",
        "    'boy': 'human_and_person', 'girl': 'human_and_person',\n",
        "    'human face': 'human_body_parts', 'human hand': 'human_body_parts', 'human head': 'human_body_parts',\n",
        "    'human arm': 'human_body_parts', 'human leg': 'human_body_parts', 'human foot': 'human_body_parts',\n",
        "    'human eye': 'human_body_parts', 'human ear': 'human_body_parts', 'human nose': 'human_body_parts',\n",
        "    'human mouth': 'human_body_parts', 'human hair': 'human_body_parts', 'human beard': 'human_body_parts',\n",
        "\n",
        "    # --- Clothing & Accessories ---\n",
        "    'clothing': 'clothing_and_accessories', 'shirt': 'clothing_and_accessories', 't-shirt': 'clothing_and_accessories',\n",
        "    'jeans': 'clothing_and_accessories', 'pants': 'clothing_and_accessories', 'dress': 'clothing_and_accessories',\n",
        "    'skirt': 'clothing_and_accessories', 'jacket': 'clothing_and_accessories', 'coat': 'clothing_and_accessories',\n",
        "    'footwear': 'clothing_and_accessories', 'boot': 'clothing_and_accessories', 'sandal': 'clothing_and_accessories',\n",
        "    'high-heeled shoe': 'clothing_and_accessories', 'handbag': 'clothing_and_accessories', 'suitcase': 'clothing_and_accessories',\n",
        "    'backpack': 'clothing_and_accessories', 'tie': 'clothing_and_accessories', 'belt': 'clothing_and_accessories',\n",
        "    'hat': 'clothing_and_accessories', 'sunglasses': 'clothing_and_accessories', 'scarf': 'clothing_and_accessories',\n",
        "    'glove': 'clothing_and_accessories', 'swimwear': 'clothing_and_accessories', 'watch': 'clothing_and_accessories',\n",
        "    'fedora': 'clothing_and_accessories', 'sombrero': 'clothing_and_accessories', 'trousers': 'clothing_and_accessories',\n",
        "    'briefcase': 'clothing_and_accessories', 'earrings': 'clothing_and_accessories', 'necklace': 'clothing_and_accessories',\n",
        "    'ring': 'clothing_and_accessories', 'wallet': 'clothing_and_accessories', 'suit': 'clothing_and_accessories',\n",
        "    'glasses': 'clothing_and_accessories', 'fashion accessory': 'clothing_and_accessories', 'shorts': 'clothing_and_accessories',\n",
        "    'brassiere': 'clothing_and_accessories', 'luggage and bags': 'clothing_and_accessories', 'helmet': 'clothing_and_accessories',\n",
        "    'high heels': 'clothing_and_accessories',\n",
        "\n",
        "    # --- Animals ---\n",
        "    'animal': 'animals', 'cat': 'animals', 'dog': 'animals', 'bird': 'animals', 'duck': 'animals',\n",
        "    'horse': 'animals', 'sheep': 'animals', 'cow': 'animals', 'elephant': 'animals', 'bear': 'animals',\n",
        "    'zebra': 'animals', 'giraffe': 'animals', 'monkey': 'animals', 'pig': 'animals', 'lion': 'animals',\n",
        "    'tiger': 'animals', 'penguin': 'animals', 'fish': 'animals', 'shark': 'animals', 'whale': 'animals',\n",
        "    'insect': 'animals', 'butterfly': 'animals', 'squirrel': 'animals', 'rabbit': 'animals', 'ant': 'animals',\n",
        "    'lizard': 'animals', 'snake': 'animals', 'spider': 'animals', 'tortoise': 'animals', 'bee': 'animals',\n",
        "    'camel': 'animals', 'crocodile': 'animals', 'dolphin': 'animals', 'eagle': 'animals', 'fox': 'animals',\n",
        "    'frog': 'animals', 'hamster': 'animals', 'koala': 'animals', 'leopard': 'animals', 'mouse': 'animals',\n",
        "    'otter': 'animals', 'owl': 'animals', 'parrot': 'animals', 'raccoon': 'animals', 'seal': 'animals',\n",
        "    'starfish': 'animals', 'swan': 'animals', 'turtle': 'animals', 'wolf': 'animals', 'goldfish': 'animals',\n",
        "    'jellyfish': 'animals', 'sea lion': 'animals', 'sea turtle': 'animals', 'seahorse': 'animals',\n",
        "    'shrimp': 'animals', 'turkey': 'animals', 'woodpecker': 'animals', 'cattle': 'animals', 'sparrow': 'animals',\n",
        "\n",
        "    # --- Vehicles ---\n",
        "    'vehicle': 'vehicles', 'car': 'vehicles', 'truck': 'vehicles', 'bus': 'vehicles', 'van': 'vehicles',\n",
        "    'motorcycle': 'vehicles', 'bicycle': 'vehicles', 'train': 'vehicles', 'airplane': 'vehicles', 'boat': 'vehicles',\n",
        "    'helicopter': 'vehicles', 'taxi': 'vehicles', 'ambulance': 'vehicles', 'tractor': 'vehicles', 'forklift': 'vehicles',\n",
        "    'limousine': 'vehicles', 'school bus': 'vehicles', 'snowmobile': 'vehicles', 'tank': 'vehicles', 'unicycle': 'vehicles',\n",
        "    'yacht': 'vehicles', 'wheel': 'vehicles', 'bicycle wheel': 'vehicles', 'tire': 'vehicles', 'auto part': 'vehicles',\n",
        "    'land vehicle': 'vehicles',\n",
        "\n",
        "    # --- Electronics & Tech ---\n",
        "    'electronics': 'electronics_and_tech', 'computer': 'electronics_and_tech', 'laptop': 'electronics_and_tech',\n",
        "    'computer keyboard': 'electronics_and_tech', 'computer mouse': 'electronics_and_tech', 'tablet computer': 'electronics_and_tech',\n",
        "    'mobile phone': 'electronics_and_tech', 'telephone': 'electronics_and_tech', 'television': 'electronics_and_tech',\n",
        "    'camera': 'electronics_and_tech', 'projector': 'electronics_and_tech', 'remote control': 'electronics_and_tech',\n",
        "    'headphones': 'electronics_and_tech', 'speaker': 'electronics_and_tech', 'microphone': 'electronics_and_tech',\n",
        "    'webcam': 'electronics_and_tech', 'computer monitor': 'electronics_and_tech', 'cassette deck': 'electronics_and_tech',\n",
        "\n",
        "    # --- Furniture ---\n",
        "    'furniture': 'furniture', 'chair': 'furniture', 'table': 'furniture', 'couch': 'furniture', 'desk': 'furniture',\n",
        "    'bed': 'furniture', 'bookcase': 'furniture', 'drawer': 'furniture', 'cabinetry': 'furniture', 'stool': 'furniture',\n",
        "    'bench': 'furniture', 'shelf': 'furniture', 'filing cabinet': 'furniture', 'armchair': 'furniture',\n",
        "    'rocking chair': 'furniture', 'sofa bed': 'furniture',\n",
        "\n",
        "    # --- Food & Drink ---\n",
        "    'food': 'food_and_drink', 'fruit': 'food_and_drink', 'apple': 'food_and_drink', 'banana': 'food_and_drink',\n",
        "    'orange': 'food_and_drink', 'grape': 'food_and_drink', 'strawberry': 'food_and_drink', 'vegetable': 'food_and_drink',\n",
        "    'carrot': 'food_and_drink', 'tomato': 'food_and_drink', 'potato': 'food_and_drink', 'bell pepper': 'food_and_drink',\n",
        "    'bread': 'food_and_drink', 'pizza': 'food_and_drink', 'pasta': 'food_and_drink', 'sandwich': 'food_and_drink',\n",
        "    'cake': 'food_and_drink', 'cookie': 'food_and_drink', 'doughnut': 'food_and_drink', 'coffee': 'food_and_drink',\n",
        "    'tea': 'food_and_drink', 'juice': 'food_and_drink', 'wine': 'food_and_drink', 'beer': 'food_and_drink', 'bottle': 'food_and_drink',\n",
        "    'sushi': 'food_and_drink', 'cheese': 'food_and_drink', 'hot dog': 'food_and_drink', 'ice cream': 'food_and_drink',\n",
        "    'pancake': 'food_and_drink', 'popcorn': 'food_and_drink', 'pretzel': 'food_and_drink', 'salad': 'food_and_drink', 'waffle': 'food_and_drink',\n",
        "    'bacon': 'food_and_drink', 'burrito': 'food_and_drink', 'taco': 'food_and_drink', 'hamburger': 'food_and_drink',\n",
        "    'candy': 'food_and_drink', 'guacamole': 'food_and_drink', 'fast food': 'food_and_drink', 'drink': 'food_and_drink',\n",
        "    'cocktail': 'food_and_drink',\n",
        "\n",
        "    # --- Kitchen & Tableware ---\n",
        "    'kitchenware': 'kitchen_and_tableware', 'plate': 'kitchen_and_tableware', 'bowl': 'kitchen_and_tableware',\n",
        "    'cup': 'kitchen_and_tableware', 'mug': 'kitchen_and_tableware', 'fork': 'kitchen_and_tableware',\n",
        "    'spoon': 'kitchen_and_tableware', 'knife': 'kitchen_and_tableware', 'cutting board': 'kitchen_and_tableware',\n",
        "    'teapot': 'kitchen_and_tableware', 'toaster': 'kitchen_and_tableware', 'microwave oven': 'kitchen_and_tableware',\n",
        "    'refrigerator': 'kitchen_and_tableware', 'oven': 'kitchen_and_tableware', 'blender': 'kitchen_and_tableware',\n",
        "    'sink': 'kitchen_and_tableware', 'wine glass': 'kitchen_and_tableware', 'frying pan': 'kitchen_and_tableware', 'ladle': 'kitchen_and_tableware',\n",
        "    'coffee cup': 'kitchen_and_tableware', 'tableware': 'kitchen_and_tableware', 'saucer': 'kitchen_and_tableware',\n",
        "\n",
        "    # --- Tools & Equipment ---\n",
        "    'tool': 'tools_and_equipment', 'hammer': 'tools_and_equipment', 'screwdriver': 'tools_and_equipment',\n",
        "    'wrench': 'tools_and_equipment', 'saw': 'tools_and_equipment', 'power tool': 'tools_and_equipment',\n",
        "    'drill': 'tools_and_equipment', 'ladder': 'tools_and_equipment', 'axe': 'tools_and_equipment', 'chisel': 'tools_and_equipment',\n",
        "\n",
        "    # --- Sports & Recreation ---\n",
        "    'sports equipment': 'sports_and_recreation', 'ball': 'sports_and_recreation', 'football': 'sports_and_recreation',\n",
        "    'baseball': 'sports_and_recreation', 'basketball': 'sports_and_recreation', 'tennis ball': 'sports_and_recreation',\n",
        "    'surfboard': 'sports_and_recreation', 'skateboard': 'sports_and_recreation', 'bicycle helmet': 'sports_and_recreation',\n",
        "    'ski': 'sports_and_recreation', 'snowboard': 'sports_and_recreation', 'dumbbell': 'sports_and_recreation',\n",
        "    'kite': 'sports_and_recreation', 'baseball bat': 'sports_and_recreation', 'baseball glove': 'sports_and_recreation',\n",
        "    'tennis racket': 'sports_and_recreation', 'billiard table': 'sports_and_recreation', 'bowling ball': 'sports_and_recreation',\n",
        "    'cricket ball': 'sports_and_recreation', 'frisbee': 'sports_and_recreation', 'golf ball': 'sports_and_recreation',\n",
        "    'rugby ball': 'sports_and_recreation', 'volleyball (ball)': 'sports_and_recreation', 'roller skates': 'sports_and_recreation',\n",
        "    'hiking equipment': 'sports_and_recreation', 'treadmill': 'sports_and_recreation',\n",
        "\n",
        "    # --- Musical Instruments ---\n",
        "    'musical instrument': 'musical_instruments', 'guitar': 'musical_instruments', 'piano': 'musical_instruments',\n",
        "    'violin': 'musical_instruments', 'drum': 'musical_instruments', 'saxophone': 'musical_instruments',\n",
        "    'trumpet': 'musical_instruments', 'flute': 'musical_instruments', 'accordion': 'musical_instruments',\n",
        "    'cello': 'musical_instruments', 'harp': 'musical_instruments', 'trombone': 'musical_instruments', 'xylophone': 'musical_instruments',\n",
        "\n",
        "    # --- Buildings & Structures ---\n",
        "    'building': 'buildings_and_structures', 'house': 'buildings_and_structures', 'skyscraper': 'buildings_and_structures',\n",
        "    'tower': 'buildings_and_structures', 'bridge': 'buildings_and_structures', 'castle': 'buildings_and_structures',\n",
        "    'church': 'buildings_and_structures', 'stadium': 'buildings_and_structures', 'stairs': 'buildings_and_structures',\n",
        "    'door': 'buildings_and_structures', 'window': 'buildings_and_structures', 'wall': 'buildings_and_structures',\n",
        "    'lighthouse': 'buildings_and_structures', 'mosque': 'buildings_and_structures', 'temple': 'buildings_and_structures',\n",
        "    'billboard': 'buildings_and_structures', 'office building': 'buildings_and_structures', 'convenience store': 'buildings_and_structures',\n",
        "\n",
        "    # --- Home & Office Goods ---\n",
        "    'office supplies': 'home_and_office_goods', 'pen': 'home_and_office_goods', 'paper': 'home_and_office_goods',\n",
        "    'book': 'home_and_office_goods', 'vase': 'home_and_office_goods', 'clock': 'home_and_office_goods',\n",
        "    'picture frame': 'home_and_office_goods', 'lamp': 'home_and_office_goods', 'potted plant': 'home_and_office_goods',\n",
        "    'mirror': 'home_and_office_goods', 'towel': 'home_and_office_goods', 'scissors': 'home_and_office_goods',\n",
        "    'candle': 'home_and_office_goods', 'pillow': 'home_and_office_goods', 'rug': 'home_and_office_goods',\n",
        "    'toilet paper': 'home_and_office_goods', 'umbrella': 'home_and_office_goods', 'houseplant': 'home_and_office_goods',\n",
        "    'flowerpot': 'home_and_office_goods', 'mechanical fan': 'home_and_office_goods', 'box': 'home_and_office_goods',\n",
        "    'poster': 'home_and_office_goods', 'wall clock': 'home_and_office_goods', 'waste container': 'home_and_office_goods',\n",
        "    'flag': 'home_and_office_goods', 'barrel': 'home_and_office_goods',\n",
        "\n",
        "    # --- Outdoor & Nature ---\n",
        "    'tree': 'outdoor_and_nature', 'flower': 'outdoor_and_nature', 'plant': 'outdoor_and_nature', 'mountain': 'outdoor_and_nature',\n",
        "    'volcano': 'outdoor_and_nature', 'beach': 'outdoor_and_nature', 'river': 'outdoor_and_nature', 'lake': 'outdoor_and_nature',\n",
        "    'sky': 'outdoor_and_nature', 'traffic light': 'outdoor_and_nature', 'fire hydrant': 'outdoor_and_nature', 'fountain': 'outdoor_and_nature',\n",
        "    'palm tree': 'outdoor_and_nature', 'rose': 'outdoor_and_nature', 'sunflower': 'outdoor_and_nature', 'maple': 'outdoor_and_nature',\n",
        "    'common fig': 'outdoor_and_nature',\n",
        "\n",
        "    # --- Toys & Games ---\n",
        "    'toy': 'toys_and_games', 'doll': 'toys_and_games', 'teddy bear': 'toys_and_games', 'lego': 'toys_and_games',\n",
        "    'dice': 'toys_and_games', 'chess': 'toys_and_games', 'puzzle': 'toys_and_games', 'swing': 'toys_and_games',\n",
        "    'balloon': 'toys_and_games',\n",
        "\n",
        "    # --- Appliances ---\n",
        "    'home appliance': 'appliances',\n",
        "\n",
        "    # --- Medical ---\n",
        "    'wheelchair': 'medical',\n",
        "\n",
        "    # --- Military & Weaponry ---\n",
        "    'rocket': 'military_and_weaponry', 'missile': 'military_and_weaponry'\n",
        "}\n",
        "DEFAULT_CATEGORY = 'other'\n",
        "# ────────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "def mount_drive():\n",
        "    \"\"\"Mount Google Drive in Colab if needed.\"\"\"\n",
        "    if not Path('/content/drive').is_mount():\n",
        "        print(\"Mounting Google Drive…\")\n",
        "        drive.mount('/content/drive', force_remount=True)\n",
        "    print(\"Google Drive mounted.\\n\")\n",
        "\n",
        "\n",
        "def load_model(url: str):\n",
        "    \"\"\"Load TF-Hub detection model and return its default signature.\"\"\"\n",
        "    print(f\"Loading model from TF-Hub: {url}\")\n",
        "    model = hub.load(url)\n",
        "    print(\"Model loaded.\\n\")\n",
        "    return model.signatures['default']\n",
        "\n",
        "\n",
        "def parse_frame_and_timestamp(fname: str):\n",
        "    \"\"\"\n",
        "    Given 'video123_0030.jpg', returns ('video123_0030', 30).\n",
        "    Falls back to (stem, 0).\n",
        "    \"\"\"\n",
        "    stem = Path(fname).stem\n",
        "    parts = stem.rsplit('_', 1)\n",
        "    if len(parts) == 2 and parts[1].isdigit():\n",
        "        mmss = parts[1]\n",
        "        secs = int(mmss[-2:]) + (int(mmss[:-2]) * 60)\n",
        "        return stem, secs\n",
        "    return stem, 0\n",
        "\n",
        "\n",
        "def process_image(path: Path, detector) -> list[dict]:\n",
        "    \"\"\"\n",
        "    Run detection on one image and return annotations matching schema.\n",
        "    \"\"\"\n",
        "    img = np.array(Image.open(path).convert('RGB'), dtype=np.float32) / 255.0\n",
        "    h, w, _ = img.shape\n",
        "    frame_id, ts = parse_frame_and_timestamp(path.name)\n",
        "\n",
        "    inputs = tf.expand_dims(tf.convert_to_tensor(img), 0)\n",
        "    results = detector(images=inputs)\n",
        "\n",
        "    scores   = results['detection_scores'].numpy().reshape(-1)\n",
        "    boxes    = results['detection_boxes'].numpy().reshape(-1, 4)\n",
        "    names    = results['detection_class_names'].numpy().reshape(-1)\n",
        "    entities = results['detection_class_entities'].numpy().reshape(-1)\n",
        "\n",
        "    labels = [nm.decode() if isinstance(nm, (bytes, bytearray)) else str(nm) for nm in names]\n",
        "    mids   = [ent.decode() if isinstance(ent, (bytes, bytearray)) else str(ent) for ent in entities]\n",
        "\n",
        "    annots, kept = [], 0\n",
        "    for i, score in enumerate(scores):\n",
        "        if kept >= MAX_OBJECTS or score < CONF_THRESHOLD:\n",
        "            continue\n",
        "        ymin, xmin, ymax, xmax = boxes[i]\n",
        "        x_min = int(xmin * w)\n",
        "        y_min = int(ymin * h)\n",
        "        x_max = int(xmax * w)\n",
        "        y_max = int(ymax * h)\n",
        "\n",
        "        segmentation = json.dumps([[[x_min, y_min], [x_max, y_min], [x_max, y_max], [x_min, y_max]]])\n",
        "        interaction = float(round(random.random(), 4))\n",
        "\n",
        "        # snake-case object_name\n",
        "        raw_name = mids[i]\n",
        "        snake_name = raw_name.lower().replace(' ', '_').replace('-', '_')\n",
        "\n",
        "        annots.append({\n",
        "            'frame_id':          frame_id,\n",
        "            'track_id':          \"\",\n",
        "            'object_id':         f\"{frame_id}_obj{kept+1}\",\n",
        "            'timestamp_sec':     ts,\n",
        "            'image_width_px':    w,\n",
        "            'image_height_px':   h,\n",
        "            'machine_id':        labels[i].lower().replace(' ', '_'),\n",
        "            'object_name':       snake_name,\n",
        "            'object_category':   'N/A',  # placeholder\n",
        "            'x_min':             x_min,\n",
        "            'y_min':             y_min,\n",
        "            'x_max':             x_max,\n",
        "            'y_max':             y_max,\n",
        "            'segmentation_mask': segmentation,\n",
        "            'confidence':        float(round(score, 4)),\n",
        "            'interaction_score': interaction,\n",
        "        })\n",
        "        kept += 1\n",
        "\n",
        "    return annots\n",
        "\n",
        "\n",
        "def main():\n",
        "    mount_drive()\n",
        "    detector = load_model(MODEL_URL)\n",
        "\n",
        "    images = sorted(STILLS_DIR.glob('*.jpg'))\n",
        "    if not images:\n",
        "        print(f\"No images found in {STILLS_DIR}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Processing {len(images)} images…\")\n",
        "    all_annots = []\n",
        "    for idx, img_path in enumerate(images, start=1):\n",
        "        print(f\" [{idx}/{len(images)}] {img_path.name}\")\n",
        "        all_annots.extend(process_image(img_path, detector))\n",
        "\n",
        "    if not all_annots:\n",
        "        print(\"No detections passed the threshold.\")\n",
        "        return\n",
        "\n",
        "    df = pd.DataFrame(all_annots)\n",
        "\n",
        "    # fill missing confidences\n",
        "    if df['confidence'].isnull().any():\n",
        "        df['confidence'].fillna(df['confidence'].median(), inplace=True)\n",
        "\n",
        "    # enforce column order\n",
        "    schema_cols = [\n",
        "        'frame_id', 'track_id', 'object_id',\n",
        "        'timestamp_sec',\n",
        "        'image_width_px', 'image_height_px',\n",
        "        'machine_id',\n",
        "        'object_name', 'object_category',\n",
        "        'x_min', 'y_min', 'x_max', 'y_max',\n",
        "        'segmentation_mask',\n",
        "        'confidence', 'interaction_score'\n",
        "    ]\n",
        "    df = df[schema_cols]\n",
        "\n",
        "    # ensure object_name is snake_case (just in case)\n",
        "    df['object_name'] = (\n",
        "        df['object_name']\n",
        "          .str.lower()\n",
        "          .str.replace(r'[^a-z0-9]+', '_', regex=True)\n",
        "          .str.strip('_')\n",
        "    )\n",
        "\n",
        "    # map categories\n",
        "    df['object_category'] = (\n",
        "        df['object_name']\n",
        "          .str.replace('_', ' ')\n",
        "          .map(TAXONOMY_MAP)\n",
        "          .fillna(DEFAULT_CATEGORY)\n",
        "    )\n",
        "\n",
        "    print(f\"\\nSaving {len(df)} annotations to {OUTPUT_CSV}\")\n",
        "    df.to_csv(OUTPUT_CSV, index=False)\n",
        "    print(\"Done.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQHWGc6l0iPG",
        "outputId": "5fce2ba8-e2e9-45b2-e1c3-76bf75a6987b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Drive mounted.\n",
            "\n",
            "Loading model from TF-Hub: https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\n",
            "Model loaded.\n",
            "\n",
            "Processing 1 images…\n",
            " [1/1] 852424-hd_1920_1080_24fps_0007.jpg\n",
            "\n",
            "Saving 8 annotations to /content/drive/MyDrive/FreeFuse_Project/Extracted_Stills/final_annotations.csv\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Label Stills"
      ],
      "metadata": {
        "id": "SG4UZ4sDQ8hJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DRAWS POLYGONS ON EXTRACTED STILLS BASED ON ANNOTATION FILE.\n",
        "# ADDS LABEL WITH CONFIDENCE SCORE.\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# === Configuration ===\n",
        "STILLS_DIR       = Path('/content/drive/MyDrive/FreeFuse_Project/Extracted_Stills')\n",
        "ANNOTATIONS_CSV  = STILLS_DIR / 'draft_annotations.csv'\n",
        "OUTPUT_DIR       = Path('/content/drive/MyDrive/FreeFuse_Project/Labeled_Stills')\n",
        "\n",
        "# Drawing settings\n",
        "BOX_COLOR        = (0, 255, 0)        # BGR green\n",
        "TEXT_COLOR       = (255, 255, 255)    # BGR white\n",
        "BOX_THICKNESS    = 2\n",
        "FONT             = cv2.FONT_HERSHEY_SIMPLEX\n",
        "FONT_SCALE       = 0.6\n",
        "LINE_TYPE        = cv2.LINE_AA\n",
        "TEXT_PADDING     = 4\n",
        "\n",
        "# === Helpers ===\n",
        "def mount_drive(mount_point: Path = Path('/content/drive')) -> None:\n",
        "    \"\"\"\n",
        "    Mount Google Drive if not already.\n",
        "    \"\"\"\n",
        "    if not mount_point.exists() or not any(mount_point.iterdir()):\n",
        "        print(\"Mounting Google Drive…\")\n",
        "        drive.mount(str(mount_point), force_remount=True)\n",
        "        print(\"Drive mounted.\")\n",
        "    else:\n",
        "        print(\"Google Drive already mounted.\")\n",
        "\n",
        "\n",
        "def load_annotations(csv_path: Path) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load annotations CSV and validate schema.\n",
        "    \"\"\"\n",
        "    if not csv_path.exists():\n",
        "        raise FileNotFoundError(f\"Annotations file not found: {csv_path}\")\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    expected = [\n",
        "        'frame_id','track_id','object_id','timestamp_sec',\n",
        "        'image_width_px','image_height_px','machine_id',\n",
        "        'object_name','object_category','x_min','y_min','x_max','y_max',\n",
        "        'segmentation_mask','confidence','interaction_score'\n",
        "    ]\n",
        "    missing = set(expected) - set(df.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing columns: {missing}\")\n",
        "    # derive image filename from frame_id\n",
        "    df['image_file'] = df['frame_id'].astype(str) + '.jpg'\n",
        "    return df\n",
        "\n",
        "\n",
        "def annotate_images(df: pd.DataFrame, stills_dir: Path, output_dir: Path) -> None:\n",
        "    \"\"\"\n",
        "    Draw polygons and labels on each still image and save.\n",
        "    \"\"\"\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    grouped = df.groupby('image_file')\n",
        "    print(f\"Found {len(grouped)} images to annotate.\")\n",
        "\n",
        "    for idx, (img_name, group) in enumerate(grouped, start=1):\n",
        "        img_path = stills_dir / img_name\n",
        "        print(f\"[{idx}/{len(grouped)}] Annotating {img_path.name}\")\n",
        "        img = cv2.imread(str(img_path))\n",
        "        if img is None:\n",
        "            print(f\"  ✗ Cannot load {img_path}\")\n",
        "            continue\n",
        "\n",
        "        for _, row in group.iterrows():\n",
        "            # parse polygon mask\n",
        "            try:\n",
        "                polygons = json.loads(row['segmentation_mask'])\n",
        "            except json.JSONDecodeError:\n",
        "                continue\n",
        "\n",
        "            # draw each polygon\n",
        "            for poly in polygons:\n",
        "                pts = [(int(x), int(y)) for x, y in poly]\n",
        "                pts_np = cv2.UMat(np.array(pts, dtype=np.int32).reshape(-1,1,2))\n",
        "                cv2.polylines(img, [pts_np.get()], isClosed=True, color=BOX_COLOR, thickness=BOX_THICKNESS)\n",
        "\n",
        "                # label at first point\n",
        "                label = f\"{row['object_name']}:{row['confidence']:.2f}\"\n",
        "                org = pts[0]\n",
        "                # compute text size\n",
        "                (tw, th), _ = cv2.getTextSize(label, FONT, FONT_SCALE, thickness=1)\n",
        "                # background rectangle\n",
        "                x0, y0 = org\n",
        "                x1, y1 = x0 + tw + TEXT_PADDING, y0 + th + TEXT_PADDING\n",
        "                cv2.rectangle(img, (x0, y0), (x1, y1), BOX_COLOR, thickness=-1)\n",
        "                # put text\n",
        "                text_org = (x0 + TEXT_PADDING//2, y0 + th)\n",
        "                cv2.putText(img, label, text_org, FONT, FONT_SCALE, TEXT_COLOR, thickness=1, lineType=LINE_TYPE)\n",
        "\n",
        "        out_path = output_dir / img_name.replace('.jpg', '_annotated.jpg')\n",
        "        cv2.imwrite(str(out_path), img)\n",
        "\n",
        "    print(\"Annotation complete.\")\n",
        "\n",
        "\n",
        "def main() -> None:\n",
        "    mount_drive()\n",
        "    df = load_annotations(ANNOTATIONS_CSV)\n",
        "    annotate_images(df, STILLS_DIR, OUTPUT_DIR)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "WmC0zzZaPf1p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cf96cf5-90bb-4e12-84a6-8d68d91f6c44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Drive already mounted.\n",
            "Found 1 images to annotate.\n",
            "[1/1] Annotating 852424-hd_1920_1080_24fps_0007.jpg\n",
            "Annotation complete.\n"
          ]
        }
      ]
    }
  ]
}