{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/hHRvxHzdOP88lnSP4IiL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thegregbeyond/FreeFuse-AI-Calbright-Project/blob/main/Object_Detection_V4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Extract Video Stills"
      ],
      "metadata": {
        "id": "5FmghcqzHyY7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8it6gaWVGPL"
      },
      "outputs": [],
      "source": [
        "# EXTRACT INDIVIDUAL STILLS FROM EACH VIDEO IN A SOURCE FOLDER.\n",
        "# CAN DEFINE STARTING SECOND AND INTERVAL BETWEEN STILLS IN SECONDS.\n",
        "\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "\n",
        "# === Configuration ===\n",
        "INPUT_DIR = Path('/content/drive/MyDrive/FreeFuse_Project/Source_Videos/Alloy Personal Training')\n",
        "OUTPUT_DIR = Path('/content/drive/MyDrive/FreeFuse_Project/Extracted_Stills')\n",
        "CAPTURE_INTERVAL_S = 4      # seconds between captures\n",
        "START_TIME_S = 1            # skip first N seconds of each video\n",
        "VIDEO_EXTS = {'.mp4', '.mov', '.avi'}\n",
        "\n",
        "\n",
        "def mount_drive(mount_point: Path = Path('/content/drive')) -> None:\n",
        "    \"\"\"\n",
        "    Mount Google Drive at the given mount_point if not already mounted.\n",
        "    \"\"\"\n",
        "    if not mount_point.exists() or not any(mount_point.iterdir()):\n",
        "        print(\"Mounting Google Drive…\")\n",
        "        drive.mount(str(mount_point), force_remount=True)\n",
        "        print(\"Drive mounted.\")\n",
        "    else:\n",
        "        print(\"Google Drive already mounted.\")\n",
        "\n",
        "\n",
        "def extract_stills(\n",
        "    input_dir: Path,\n",
        "    output_dir: Path,\n",
        "    interval_s: float,\n",
        "    start_s: float\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Extract frames every `interval_s` seconds from each video in `input_dir`,\n",
        "    skipping the first `start_s` seconds, and save them to `output_dir` with\n",
        "    filenames as <video_stem>_<total_seconds_padded_4d>.jpg.\n",
        "    \"\"\"\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    video_files = [f for f in sorted(input_dir.iterdir()) if f.suffix.lower() in VIDEO_EXTS]\n",
        "\n",
        "    if not video_files:\n",
        "        print(f\"No videos found in {input_dir}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(video_files)} videos in {input_dir}\")\n",
        "    for idx, video_file in enumerate(video_files, start=1):\n",
        "        print(f\"[{idx}/{len(video_files)}] Processing '{video_file.name}'\")\n",
        "        cap = cv2.VideoCapture(str(video_file))\n",
        "        if not cap.isOpened():\n",
        "            print(f\"  ✗ Could not open {video_file.name}, skipping.\")\n",
        "            continue\n",
        "\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
        "        start_frame = int(start_s * fps)\n",
        "        if start_frame > 0:\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
        "            print(f\"  → Skipped first {start_s}s ({start_frame} frames)\")\n",
        "\n",
        "        next_capture = start_s\n",
        "        saved_count = 0\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            current_s = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0\n",
        "            if current_s >= next_capture:\n",
        "                total_sec = int(current_s)\n",
        "                timestamp = f\"{total_sec:04d}\"\n",
        "                filename = f\"{video_file.stem}_{timestamp}.jpg\"\n",
        "                filepath = output_dir / filename\n",
        "                cv2.imwrite(str(filepath), frame)\n",
        "                print(f\"  ✔ Saved {filename}\")\n",
        "                saved_count += 1\n",
        "                next_capture += interval_s\n",
        "\n",
        "        cap.release()\n",
        "        print(f\"  Completed '{video_file.name}', saved {saved_count} frames.\\n\")\n",
        "\n",
        "    print(\"All videos processed.\")\n",
        "\n",
        "\n",
        "def main() -> None:\n",
        "    mount_drive()\n",
        "    extract_stills(INPUT_DIR, OUTPUT_DIR, CAPTURE_INTERVAL_S, START_TIME_S)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Object Detection"
      ],
      "metadata": {
        "id": "a_9DCsIuJdxm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Annotation File Schema:**\n",
        "* frame_id (string): Unique frame identifier (e.g., 'video123_0030').\n",
        "* track_id (string): Ppersistent ID for unique object instance across multiple frames (for future use)\n",
        "* object_id (string): Unique identifier for object within this specific frame (e.g., 'video123_0030_obj1').\n",
        "* timestamp_sec (integer): Time offset in seconds when still was captured.\n",
        "* image_width_px (integer): Width of still image in pixels.\n",
        "* image_height_px (integer): Height of still image in pixels.\n",
        "* machine_id (string): Machine-generated ID for detected object class from knowledge graph (e.g., '/m/0271t').\n",
        "* object_name (string): Detected object label in its canonical form (e.g., 'coffee_mug').\n",
        "* object_category (string): Gigh-level grouping for object (e.g., 'electronics', 'furniture').\n",
        "* x_min (integer): Left coordinate of the bounding box in pixels.\n",
        "* y_min (integer): Top coordinate of the bounding box in pixels.\n",
        "* x_max (integer): Right coordinate of the bounding box in pixels.\n",
        "* y_max (integer): Bottom coordinate of the bounding box in pixels.\n",
        "* segmentation_mask (string): Pixel-wise mask for object, stored as array of polygon coordinates (e.g., '[[[x1,y1],[x2,y2],...]]').\n",
        "* confidence (float): Model's confidence score for initial detection (0.0–1.0).\n",
        "* interaction_score (float): Score (real or mocked) representing object's potential for user engagement (0.0–1.0)."
      ],
      "metadata": {
        "id": "uVKANrBIYOdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATES EXPANDED ANNOTATION FILE BASED ON FASTER R-CNN MODEL.\n",
        "# BASED ON THE OPEN IMAGES V4 MODEL WHICH INCLUDES 600 OBJECT CLASSES.\n",
        "# OBJECT CATEGORY IS POPULATED BASED ON CANONICAL MAPPING OF THOSE CLASSES.\n",
        "# NOTE THAT THIS IS A HEAVY-WEIGHT ALGORITHM AND MAY RUN SLOW.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "import json\n",
        "import random\n",
        "\n",
        "# ─── Configuration ───────────────────────────────────────────────────────────────\n",
        "STILLS_DIR      = Path('/content/drive/MyDrive/FreeFuse_Project/Extracted_Stills')\n",
        "OUTPUT_CSV      = STILLS_DIR / 'final_annotations.csv'\n",
        "MODEL_URL       = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"\n",
        "MAX_OBJECTS     = 10\n",
        "CONF_THRESHOLD  = 0.5\n",
        "\n",
        "# ─── Taxonomy Mapping ───────────────────────────────────────────────────────────\n",
        "# Maps lower-cased object names to high-level categories\n",
        "TAXONOMY_MAP = {\n",
        "    # --- Human & Person ---\n",
        "    'person': 'human_and_person', 'man': 'human_and_person', 'woman': 'human_and_person',\n",
        "    'boy': 'human_and_person', 'girl': 'human_and_person',\n",
        "    'human face': 'human_body_parts', 'human hand': 'human_body_parts', 'human head': 'human_body_parts',\n",
        "    'human arm': 'human_body_parts', 'human leg': 'human_body_parts', 'human foot': 'human_body_parts',\n",
        "    'human eye': 'human_body_parts', 'human ear': 'human_body_parts', 'human nose': 'human_body_parts',\n",
        "    'human mouth': 'human_body_parts', 'human hair': 'human_body_parts', 'human beard': 'human_body_parts',\n",
        "\n",
        "    # --- Clothing & Accessories ---\n",
        "    'clothing': 'clothing_and_accessories', 'shirt': 'clothing_and_accessories', 't-shirt': 'clothing_and_accessories',\n",
        "    'jeans': 'clothing_and_accessories', 'pants': 'clothing_and_accessories', 'dress': 'clothing_and_accessories',\n",
        "    'skirt': 'clothing_and_accessories', 'jacket': 'clothing_and_accessories', 'coat': 'clothing_and_accessories',\n",
        "    'footwear': 'clothing_and_accessories', 'boot': 'clothing_and_accessories', 'sandal': 'clothing_and_accessories',\n",
        "    'high-heeled shoe': 'clothing_and_accessories', 'handbag': 'clothing_and_accessories', 'suitcase': 'clothing_and_accessories',\n",
        "    'backpack': 'clothing_and_accessories', 'tie': 'clothing_and_accessories', 'belt': 'clothing_and_accessories',\n",
        "    'hat': 'clothing_and_accessories', 'sunglasses': 'clothing_and_accessories', 'scarf': 'clothing_and_accessories',\n",
        "    'glove': 'clothing_and_accessories', 'swimwear': 'clothing_and_accessories', 'watch': 'clothing_and_accessories',\n",
        "    'fedora': 'clothing_and_accessories', 'sombrero': 'clothing_and_accessories', 'trousers': 'clothing_and_accessories',\n",
        "    'briefcase': 'clothing_and_accessories', 'earrings': 'clothing_and_accessories', 'necklace': 'clothing_and_accessories',\n",
        "    'ring': 'clothing_and_accessories', 'wallet': 'clothing_and_accessories', 'suit': 'clothing_and_accessories',\n",
        "    'glasses': 'clothing_and_accessories', 'fashion accessory': 'clothing_and_accessories', 'shorts': 'clothing_and_accessories',\n",
        "    'brassiere': 'clothing_and_accessories', 'luggage and bags': 'clothing_and_accessories', 'helmet': 'clothing_and_accessories',\n",
        "    'high heels': 'clothing_and_accessories',\n",
        "\n",
        "    # --- Animals ---\n",
        "    'animal': 'animals', 'cat': 'animals', 'dog': 'animals', 'bird': 'animals', 'duck': 'animals',\n",
        "    'horse': 'animals', 'sheep': 'animals', 'cow': 'animals', 'elephant': 'animals', 'bear': 'animals',\n",
        "    'zebra': 'animals', 'giraffe': 'animals', 'monkey': 'animals', 'pig': 'animals', 'lion': 'animals',\n",
        "    'tiger': 'animals', 'penguin': 'animals', 'fish': 'animals', 'shark': 'animals', 'whale': 'animals',\n",
        "    'insect': 'animals', 'butterfly': 'animals', 'squirrel': 'animals', 'rabbit': 'animals', 'ant': 'animals',\n",
        "    'lizard': 'animals', 'snake': 'animals', 'spider': 'animals', 'tortoise': 'animals', 'bee': 'animals',\n",
        "    'camel': 'animals', 'crocodile': 'animals', 'dolphin': 'animals', 'eagle': 'animals', 'fox': 'animals',\n",
        "    'frog': 'animals', 'hamster': 'animals', 'koala': 'animals', 'leopard': 'animals', 'mouse': 'animals',\n",
        "    'otter': 'animals', 'owl': 'animals', 'parrot': 'animals', 'raccoon': 'animals', 'seal': 'animals',\n",
        "    'starfish': 'animals', 'swan': 'animals', 'turtle': 'animals', 'wolf': 'animals', 'goldfish': 'animals',\n",
        "    'jellyfish': 'animals', 'sea lion': 'animals', 'sea turtle': 'animals', 'seahorse': 'animals',\n",
        "    'shrimp': 'animals', 'turkey': 'animals', 'woodpecker': 'animals', 'cattle': 'animals', 'sparrow': 'animals',\n",
        "\n",
        "    # --- Vehicles ---\n",
        "    'vehicle': 'vehicles', 'car': 'vehicles', 'truck': 'vehicles', 'bus': 'vehicles', 'van': 'vehicles',\n",
        "    'motorcycle': 'vehicles', 'bicycle': 'vehicles', 'train': 'vehicles', 'airplane': 'vehicles', 'boat': 'vehicles',\n",
        "    'helicopter': 'vehicles', 'taxi': 'vehicles', 'ambulance': 'vehicles', 'tractor': 'vehicles', 'forklift': 'vehicles',\n",
        "    'limousine': 'vehicles', 'school bus': 'vehicles', 'snowmobile': 'vehicles', 'tank': 'vehicles', 'unicycle': 'vehicles',\n",
        "    'yacht': 'vehicles', 'wheel': 'vehicles', 'bicycle wheel': 'vehicles', 'tire': 'vehicles', 'auto part': 'vehicles',\n",
        "    'land vehicle': 'vehicles',\n",
        "\n",
        "    # --- Electronics & Tech ---\n",
        "    'electronics': 'electronics_and_tech', 'computer': 'electronics_and_tech', 'laptop': 'electronics_and_tech',\n",
        "    'computer keyboard': 'electronics_and_tech', 'computer mouse': 'electronics_and_tech', 'tablet computer': 'electronics_and_tech',\n",
        "    'mobile phone': 'electronics_and_tech', 'telephone': 'electronics_and_tech', 'television': 'electronics_and_tech',\n",
        "    'camera': 'electronics_and_tech', 'projector': 'electronics_and_tech', 'remote control': 'electronics_and_tech',\n",
        "    'headphones': 'electronics_and_tech', 'speaker': 'electronics_and_tech', 'microphone': 'electronics_and_tech',\n",
        "    'webcam': 'electronics_and_tech', 'computer monitor': 'electronics_and_tech', 'cassette deck': 'electronics_and_tech',\n",
        "\n",
        "    # --- Furniture ---\n",
        "    'furniture': 'furniture', 'chair': 'furniture', 'table': 'furniture', 'couch': 'furniture', 'desk': 'furniture',\n",
        "    'bed': 'furniture', 'bookcase': 'furniture', 'drawer': 'furniture', 'cabinetry': 'furniture', 'stool': 'furniture',\n",
        "    'bench': 'furniture', 'shelf': 'furniture', 'filing cabinet': 'furniture', 'armchair': 'furniture',\n",
        "    'rocking chair': 'furniture', 'sofa bed': 'furniture',\n",
        "\n",
        "    # --- Food & Drink ---\n",
        "    'food': 'food_and_drink', 'fruit': 'food_and_drink', 'apple': 'food_and_drink', 'banana': 'food_and_drink',\n",
        "    'orange': 'food_and_drink', 'grape': 'food_and_drink', 'strawberry': 'food_and_drink', 'vegetable': 'food_and_drink',\n",
        "    'carrot': 'food_and_drink', 'tomato': 'food_and_drink', 'potato': 'food_and_drink', 'bell pepper': 'food_and_drink',\n",
        "    'bread': 'food_and_drink', 'pizza': 'food_and_drink', 'pasta': 'food_and_drink', 'sandwich': 'food_and_drink',\n",
        "    'cake': 'food_and_drink', 'cookie': 'food_and_drink', 'doughnut': 'food_and_drink', 'coffee': 'food_and_drink',\n",
        "    'tea': 'food_and_drink', 'juice': 'food_and_drink', 'wine': 'food_and_drink', 'beer': 'food_and_drink', 'bottle': 'food_and_drink',\n",
        "    'sushi': 'food_and_drink', 'cheese': 'food_and_drink', 'hot dog': 'food_and_drink', 'ice cream': 'food_and_drink',\n",
        "    'pancake': 'food_and_drink', 'popcorn': 'food_and_drink', 'pretzel': 'food_and_drink', 'salad': 'food_and_drink', 'waffle': 'food_and_drink',\n",
        "    'bacon': 'food_and_drink', 'burrito': 'food_and_drink', 'taco': 'food_and_drink', 'hamburger': 'food_and_drink',\n",
        "    'candy': 'food_and_drink', 'guacamole': 'food_and_drink', 'fast food': 'food_and_drink', 'drink': 'food_and_drink',\n",
        "    'cocktail': 'food_and_drink',\n",
        "\n",
        "    # --- Kitchen & Tableware ---\n",
        "    'kitchenware': 'kitchen_and_tableware', 'plate': 'kitchen_and_tableware', 'bowl': 'kitchen_and_tableware',\n",
        "    'cup': 'kitchen_and_tableware', 'mug': 'kitchen_and_tableware', 'fork': 'kitchen_and_tableware',\n",
        "    'spoon': 'kitchen_and_tableware', 'knife': 'kitchen_and_tableware', 'cutting board': 'kitchen_and_tableware',\n",
        "    'teapot': 'kitchen_and_tableware', 'toaster': 'kitchen_and_tableware', 'microwave oven': 'kitchen_and_tableware',\n",
        "    'refrigerator': 'kitchen_and_tableware', 'oven': 'kitchen_and_tableware', 'blender': 'kitchen_and_tableware',\n",
        "    'sink': 'kitchen_and_tableware', 'wine glass': 'kitchen_and_tableware', 'frying pan': 'kitchen_and_tableware', 'ladle': 'kitchen_and_tableware',\n",
        "    'coffee cup': 'kitchen_and_tableware', 'tableware': 'kitchen_and_tableware', 'saucer': 'kitchen_and_tableware',\n",
        "\n",
        "    # --- Tools & Equipment ---\n",
        "    'tool': 'tools_and_equipment', 'hammer': 'tools_and_equipment', 'screwdriver': 'tools_and_equipment',\n",
        "    'wrench': 'tools_and_equipment', 'saw': 'tools_and_equipment', 'power tool': 'tools_and_equipment',\n",
        "    'drill': 'tools_and_equipment', 'ladder': 'tools_and_equipment', 'axe': 'tools_and_equipment', 'chisel': 'tools_and_equipment',\n",
        "\n",
        "    # --- Sports & Recreation ---\n",
        "    'sports equipment': 'sports_and_recreation', 'ball': 'sports_and_recreation', 'football': 'sports_and_recreation',\n",
        "    'baseball': 'sports_and_recreation', 'basketball': 'sports_and_recreation', 'tennis ball': 'sports_and_recreation',\n",
        "    'surfboard': 'sports_and_recreation', 'skateboard': 'sports_and_recreation', 'bicycle helmet': 'sports_and_recreation',\n",
        "    'ski': 'sports_and_recreation', 'snowboard': 'sports_and_recreation', 'dumbbell': 'sports_and_recreation',\n",
        "    'kite': 'sports_and_recreation', 'baseball bat': 'sports_and_recreation', 'baseball glove': 'sports_and_recreation',\n",
        "    'tennis racket': 'sports_and_recreation', 'billiard table': 'sports_and_recreation', 'bowling ball': 'sports_and_recreation',\n",
        "    'cricket ball': 'sports_and_recreation', 'frisbee': 'sports_and_recreation', 'golf ball': 'sports_and_recreation',\n",
        "    'rugby ball': 'sports_and_recreation', 'volleyball (ball)': 'sports_and_recreation', 'roller skates': 'sports_and_recreation',\n",
        "    'hiking equipment': 'sports_and_recreation', 'treadmill': 'sports_and_recreation',\n",
        "\n",
        "    # --- Musical Instruments ---\n",
        "    'musical instrument': 'musical_instruments', 'guitar': 'musical_instruments', 'piano': 'musical_instruments',\n",
        "    'violin': 'musical_instruments', 'drum': 'musical_instruments', 'saxophone': 'musical_instruments',\n",
        "    'trumpet': 'musical_instruments', 'flute': 'musical_instruments', 'accordion': 'musical_instruments',\n",
        "    'cello': 'musical_instruments', 'harp': 'musical_instruments', 'trombone': 'musical_instruments', 'xylophone': 'musical_instruments',\n",
        "\n",
        "    # --- Buildings & Structures ---\n",
        "    'building': 'buildings_and_structures', 'house': 'buildings_and_structures', 'skyscraper': 'buildings_and_structures',\n",
        "    'tower': 'buildings_and_structures', 'bridge': 'buildings_and_structures', 'castle': 'buildings_and_structures',\n",
        "    'church': 'buildings_and_structures', 'stadium': 'buildings_and_structures', 'stairs': 'buildings_and_structures',\n",
        "    'door': 'buildings_and_structures', 'window': 'buildings_and_structures', 'wall': 'buildings_and_structures',\n",
        "    'lighthouse': 'buildings_and_structures', 'mosque': 'buildings_and_structures', 'temple': 'buildings_and_structures',\n",
        "    'billboard': 'buildings_and_structures', 'office building': 'buildings_and_structures', 'convenience store': 'buildings_and_structures',\n",
        "\n",
        "    # --- Home & Office Goods ---\n",
        "    'office supplies': 'home_and_office_goods', 'pen': 'home_and_office_goods', 'paper': 'home_and_office_goods',\n",
        "    'book': 'home_and_office_goods', 'vase': 'home_and_office_goods', 'clock': 'home_and_office_goods',\n",
        "    'picture frame': 'home_and_office_goods', 'lamp': 'home_and_office_goods', 'potted plant': 'home_and_office_goods',\n",
        "    'mirror': 'home_and_office_goods', 'towel': 'home_and_office_goods', 'scissors': 'home_and_office_goods',\n",
        "    'candle': 'home_and_office_goods', 'pillow': 'home_and_office_goods', 'rug': 'home_and_office_goods',\n",
        "    'toilet paper': 'home_and_office_goods', 'umbrella': 'home_and_office_goods', 'houseplant': 'home_and_office_goods',\n",
        "    'flowerpot': 'home_and_office_goods', 'mechanical fan': 'home_and_office_goods', 'box': 'home_and_office_goods',\n",
        "    'poster': 'home_and_office_goods', 'wall clock': 'home_and_office_goods', 'waste container': 'home_and_office_goods',\n",
        "    'flag': 'home_and_office_goods', 'barrel': 'home_and_office_goods',\n",
        "\n",
        "    # --- Outdoor & Nature ---\n",
        "    'tree': 'outdoor_and_nature', 'flower': 'outdoor_and_nature', 'plant': 'outdoor_and_nature', 'mountain': 'outdoor_and_nature',\n",
        "    'volcano': 'outdoor_and_nature', 'beach': 'outdoor_and_nature', 'river': 'outdoor_and_nature', 'lake': 'outdoor_and_nature',\n",
        "    'sky': 'outdoor_and_nature', 'traffic light': 'outdoor_and_nature', 'fire hydrant': 'outdoor_and_nature', 'fountain': 'outdoor_and_nature',\n",
        "    'palm tree': 'outdoor_and_nature', 'rose': 'outdoor_and_nature', 'sunflower': 'outdoor_and_nature', 'maple': 'outdoor_and_nature',\n",
        "    'common fig': 'outdoor_and_nature',\n",
        "\n",
        "    # --- Toys & Games ---\n",
        "    'toy': 'toys_and_games', 'doll': 'toys_and_games', 'teddy bear': 'toys_and_games', 'lego': 'toys_and_games',\n",
        "    'dice': 'toys_and_games', 'chess': 'toys_and_games', 'puzzle': 'toys_and_games', 'swing': 'toys_and_games',\n",
        "    'balloon': 'toys_and_games',\n",
        "\n",
        "    # --- Appliances ---\n",
        "    'home appliance': 'appliances',\n",
        "\n",
        "    # --- Medical ---\n",
        "    'wheelchair': 'medical',\n",
        "\n",
        "    # --- Military & Weaponry ---\n",
        "    'rocket': 'military_and_weaponry', 'missile': 'military_and_weaponry'\n",
        "}\n",
        "DEFAULT_CATEGORY = 'other'\n",
        "# ────────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "def mount_drive():\n",
        "    \"\"\"Mount Google Drive in Colab if needed.\"\"\"\n",
        "    if not Path('/content/drive').is_mount():\n",
        "        print(\"Mounting Google Drive…\")\n",
        "        drive.mount('/content/drive', force_remount=True)\n",
        "    print(\"Google Drive mounted.\\n\")\n",
        "\n",
        "\n",
        "def load_model(url: str):\n",
        "    \"\"\"Load TF-Hub detection model and return its default signature.\"\"\"\n",
        "    print(f\"Loading model from TF-Hub: {url}\")\n",
        "    model = hub.load(url)\n",
        "    print(\"Model loaded.\\n\")\n",
        "    return model.signatures['default']\n",
        "\n",
        "\n",
        "def parse_frame_and_timestamp(fname: str):\n",
        "    \"\"\"\n",
        "    Given 'video123_0030.jpg', returns ('video123_0030', 30).\n",
        "    Falls back to (stem, 0).\n",
        "    \"\"\"\n",
        "    stem = Path(fname).stem\n",
        "    parts = stem.rsplit('_', 1)\n",
        "    if len(parts) == 2 and parts[1].isdigit():\n",
        "        mmss = parts[1]\n",
        "        secs = int(mmss[-2:]) + (int(mmss[:-2]) * 60)\n",
        "        return stem, secs\n",
        "    return stem, 0\n",
        "\n",
        "\n",
        "def process_image(path: Path, detector) -> list[dict]:\n",
        "    \"\"\"\n",
        "    Run detection on one image and return annotations matching schema.\n",
        "    \"\"\"\n",
        "    img = np.array(Image.open(path).convert('RGB'), dtype=np.float32) / 255.0\n",
        "    h, w, _ = img.shape\n",
        "    frame_id, ts = parse_frame_and_timestamp(path.name)\n",
        "\n",
        "    inputs = tf.expand_dims(tf.convert_to_tensor(img), 0)\n",
        "    results = detector(images=inputs)\n",
        "\n",
        "    scores   = results['detection_scores'].numpy().reshape(-1)\n",
        "    boxes    = results['detection_boxes'].numpy().reshape(-1, 4)\n",
        "    names    = results['detection_class_names'].numpy().reshape(-1)\n",
        "    entities = results['detection_class_entities'].numpy().reshape(-1)\n",
        "\n",
        "    labels = [nm.decode() if isinstance(nm, (bytes, bytearray)) else str(nm) for nm in names]\n",
        "    mids   = [ent.decode() if isinstance(ent, (bytes, bytearray)) else str(ent) for ent in entities]\n",
        "\n",
        "    annots, kept = [], 0\n",
        "    for i, score in enumerate(scores):\n",
        "        if kept >= MAX_OBJECTS or score < CONF_THRESHOLD:\n",
        "            continue\n",
        "        ymin, xmin, ymax, xmax = boxes[i]\n",
        "        x_min = int(xmin * w)\n",
        "        y_min = int(ymin * h)\n",
        "        x_max = int(xmax * w)\n",
        "        y_max = int(ymax * h)\n",
        "\n",
        "        segmentation = json.dumps([[[x_min, y_min], [x_max, y_min], [x_max, y_max], [x_min, y_max]]])\n",
        "        interaction = float(round(random.random(), 4))\n",
        "\n",
        "        # snake-case object_name\n",
        "        raw_name = mids[i]\n",
        "        snake_name = raw_name.lower().replace(' ', '_').replace('-', '_')\n",
        "\n",
        "        annots.append({\n",
        "            'frame_id':          frame_id,\n",
        "            'track_id':          \"\",\n",
        "            'object_id':         f\"{frame_id}_obj{kept+1}\",\n",
        "            'timestamp_sec':     ts,\n",
        "            'image_width_px':    w,\n",
        "            'image_height_px':   h,\n",
        "            'machine_id':        labels[i].lower().replace(' ', '_'),\n",
        "            'object_name':       snake_name,\n",
        "            'object_category':   'N/A',  # placeholder\n",
        "            'x_min':             x_min,\n",
        "            'y_min':             y_min,\n",
        "            'x_max':             x_max,\n",
        "            'y_max':             y_max,\n",
        "            'segmentation_mask': segmentation,\n",
        "            'confidence':        float(round(score, 4)),\n",
        "            'interaction_score': interaction,\n",
        "        })\n",
        "        kept += 1\n",
        "\n",
        "    return annots\n",
        "\n",
        "\n",
        "def main():\n",
        "    mount_drive()\n",
        "    detector = load_model(MODEL_URL)\n",
        "\n",
        "    images = sorted(STILLS_DIR.glob('*.jpg'))\n",
        "    if not images:\n",
        "        print(f\"No images found in {STILLS_DIR}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Processing {len(images)} images…\")\n",
        "    all_annots = []\n",
        "    for idx, img_path in enumerate(images, start=1):\n",
        "        print(f\" [{idx}/{len(images)}] {img_path.name}\")\n",
        "        all_annots.extend(process_image(img_path, detector))\n",
        "\n",
        "    if not all_annots:\n",
        "        print(\"No detections passed the threshold.\")\n",
        "        return\n",
        "\n",
        "    df = pd.DataFrame(all_annots)\n",
        "\n",
        "    # fill missing confidences\n",
        "    if df['confidence'].isnull().any():\n",
        "        df['confidence'].fillna(df['confidence'].median(), inplace=True)\n",
        "\n",
        "    # enforce column order\n",
        "    schema_cols = [\n",
        "        'frame_id', 'track_id', 'object_id',\n",
        "        'timestamp_sec',\n",
        "        'image_width_px', 'image_height_px',\n",
        "        'machine_id',\n",
        "        'object_name', 'object_category',\n",
        "        'x_min', 'y_min', 'x_max', 'y_max',\n",
        "        'segmentation_mask',\n",
        "        'confidence', 'interaction_score'\n",
        "    ]\n",
        "    df = df[schema_cols]\n",
        "\n",
        "    # ensure object_name is snake_case (just in case)\n",
        "    df['object_name'] = (\n",
        "        df['object_name']\n",
        "          .str.lower()\n",
        "          .str.replace(r'[^a-z0-9]+', '_', regex=True)\n",
        "          .str.strip('_')\n",
        "    )\n",
        "\n",
        "    # map categories\n",
        "    df['object_category'] = (\n",
        "        df['object_name']\n",
        "          .str.replace('_', ' ')\n",
        "          .map(TAXONOMY_MAP)\n",
        "          .fillna(DEFAULT_CATEGORY)\n",
        "    )\n",
        "\n",
        "    print(f\"\\nSaving {len(df)} annotations to {OUTPUT_CSV}\")\n",
        "    df.to_csv(OUTPUT_CSV, index=False)\n",
        "    print(\"Done.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQHWGc6l0iPG",
        "outputId": "5fce2ba8-e2e9-45b2-e1c3-76bf75a6987b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Drive mounted.\n",
            "\n",
            "Loading model from TF-Hub: https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\n",
            "Model loaded.\n",
            "\n",
            "Processing 1 images…\n",
            " [1/1] 852424-hd_1920_1080_24fps_0007.jpg\n",
            "\n",
            "Saving 8 annotations to /content/drive/MyDrive/FreeFuse_Project/Extracted_Stills/final_annotations.csv\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Label Stills"
      ],
      "metadata": {
        "id": "SG4UZ4sDQ8hJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DRAWS POLYGONS ON EXTRACTED STILLS BASED ON ANNOTATION FILE.\n",
        "# ADDS LABEL WITH CONFIDENCE SCORE.\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# === Configuration ===\n",
        "STILLS_DIR       = Path('/content/drive/MyDrive/FreeFuse_Project/Extracted_Stills')\n",
        "ANNOTATIONS_CSV  = STILLS_DIR / 'draft_annotations.csv'\n",
        "OUTPUT_DIR       = Path('/content/drive/MyDrive/FreeFuse_Project/Labeled_Stills')\n",
        "\n",
        "# Drawing settings\n",
        "BOX_COLOR        = (0, 255, 0)        # BGR green\n",
        "TEXT_COLOR       = (255, 255, 255)    # BGR white\n",
        "BOX_THICKNESS    = 2\n",
        "FONT             = cv2.FONT_HERSHEY_SIMPLEX\n",
        "FONT_SCALE       = 0.6\n",
        "LINE_TYPE        = cv2.LINE_AA\n",
        "TEXT_PADDING     = 4\n",
        "\n",
        "# === Helpers ===\n",
        "def mount_drive(mount_point: Path = Path('/content/drive')) -> None:\n",
        "    \"\"\"\n",
        "    Mount Google Drive if not already.\n",
        "    \"\"\"\n",
        "    if not mount_point.exists() or not any(mount_point.iterdir()):\n",
        "        print(\"Mounting Google Drive…\")\n",
        "        drive.mount(str(mount_point), force_remount=True)\n",
        "        print(\"Drive mounted.\")\n",
        "    else:\n",
        "        print(\"Google Drive already mounted.\")\n",
        "\n",
        "\n",
        "def load_annotations(csv_path: Path) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load annotations CSV and validate schema.\n",
        "    \"\"\"\n",
        "    if not csv_path.exists():\n",
        "        raise FileNotFoundError(f\"Annotations file not found: {csv_path}\")\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    expected = [\n",
        "        'frame_id','track_id','object_id','timestamp_sec',\n",
        "        'image_width_px','image_height_px','machine_id',\n",
        "        'object_name','object_category','x_min','y_min','x_max','y_max',\n",
        "        'segmentation_mask','confidence','interaction_score'\n",
        "    ]\n",
        "    missing = set(expected) - set(df.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing columns: {missing}\")\n",
        "    # derive image filename from frame_id\n",
        "    df['image_file'] = df['frame_id'].astype(str) + '.jpg'\n",
        "    return df\n",
        "\n",
        "\n",
        "def annotate_images(df: pd.DataFrame, stills_dir: Path, output_dir: Path) -> None:\n",
        "    \"\"\"\n",
        "    Draw polygons and labels on each still image and save.\n",
        "    \"\"\"\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    grouped = df.groupby('image_file')\n",
        "    print(f\"Found {len(grouped)} images to annotate.\")\n",
        "\n",
        "    for idx, (img_name, group) in enumerate(grouped, start=1):\n",
        "        img_path = stills_dir / img_name\n",
        "        print(f\"[{idx}/{len(grouped)}] Annotating {img_path.name}\")\n",
        "        img = cv2.imread(str(img_path))\n",
        "        if img is None:\n",
        "            print(f\"  ✗ Cannot load {img_path}\")\n",
        "            continue\n",
        "\n",
        "        for _, row in group.iterrows():\n",
        "            # parse polygon mask\n",
        "            try:\n",
        "                polygons = json.loads(row['segmentation_mask'])\n",
        "            except json.JSONDecodeError:\n",
        "                continue\n",
        "\n",
        "            # draw each polygon\n",
        "            for poly in polygons:\n",
        "                pts = [(int(x), int(y)) for x, y in poly]\n",
        "                pts_np = cv2.UMat(np.array(pts, dtype=np.int32).reshape(-1,1,2))\n",
        "                cv2.polylines(img, [pts_np.get()], isClosed=True, color=BOX_COLOR, thickness=BOX_THICKNESS)\n",
        "\n",
        "                # label at first point\n",
        "                label = f\"{row['object_name']}:{row['confidence']:.2f}\"\n",
        "                org = pts[0]\n",
        "                # compute text size\n",
        "                (tw, th), _ = cv2.getTextSize(label, FONT, FONT_SCALE, thickness=1)\n",
        "                # background rectangle\n",
        "                x0, y0 = org\n",
        "                x1, y1 = x0 + tw + TEXT_PADDING, y0 + th + TEXT_PADDING\n",
        "                cv2.rectangle(img, (x0, y0), (x1, y1), BOX_COLOR, thickness=-1)\n",
        "                # put text\n",
        "                text_org = (x0 + TEXT_PADDING//2, y0 + th)\n",
        "                cv2.putText(img, label, text_org, FONT, FONT_SCALE, TEXT_COLOR, thickness=1, lineType=LINE_TYPE)\n",
        "\n",
        "        out_path = output_dir / img_name.replace('.jpg', '_annotated.jpg')\n",
        "        cv2.imwrite(str(out_path), img)\n",
        "\n",
        "    print(\"Annotation complete.\")\n",
        "\n",
        "\n",
        "def main() -> None:\n",
        "    mount_drive()\n",
        "    df = load_annotations(ANNOTATIONS_CSV)\n",
        "    annotate_images(df, STILLS_DIR, OUTPUT_DIR)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "WmC0zzZaPf1p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cf96cf5-90bb-4e12-84a6-8d68d91f6c44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Drive already mounted.\n",
            "Found 1 images to annotate.\n",
            "[1/1] Annotating 852424-hd_1920_1080_24fps_0007.jpg\n",
            "Annotation complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) Generate Proxy Interaction Scores"
      ],
      "metadata": {
        "id": "L5DoHXhcWHjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "# ─── USER CONFIG ────────────────────────────────────────────────────────────────\n",
        "DRIVE_MOUNT_POINT = \"/content/drive\"\n",
        "INPUT_CSV_PATH    = Path(f\"{DRIVE_MOUNT_POINT}/MyDrive/FreeFuse_Project/Extracted_Stills/temp_annotations.csv\")\n",
        "OUTPUT_CSV_PATH   = INPUT_CSV_PATH.parent / \"final_annotations.csv\"\n",
        "# ────────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "# Base scores by category\n",
        "CATEGORY_BASE = {\n",
        "    'electronics_and_tech':     0.70,\n",
        "    'food_and_drink':           0.60,\n",
        "    'clothing_and_accessories': 0.50,\n",
        "    'kitchen_and_tableware':    0.50,\n",
        "    'sports_and_recreation':    0.50,\n",
        "    'home_and_office_goods':    0.40,\n",
        "    'vehicles':                 0.30,\n",
        "    'tools_and_equipment':      0.30,\n",
        "    'furniture':                0.20,\n",
        "    'toys_and_games':           0.40,\n",
        "    'musical_instruments':      0.40,\n",
        "    'other':                    0.10,\n",
        "}\n",
        "DEFAULT_BASE = 0.10\n",
        "\n",
        "# Modifier maxima\n",
        "CENTRALITY_BONUS_MAX   = 0.20\n",
        "PROMINENCE_BONUS_MAX   = 0.15\n",
        "HALF_DIAGONAL_DISTANCE = np.sqrt(2) / 2  # ≈0.7071\n",
        "\n",
        "# ─── DRIVE ───────────────────────────────────────────────────────────────────────\n",
        "def mount_drive():\n",
        "    if not Path(DRIVE_MOUNT_POINT).is_mount():\n",
        "        print(\"Mounting Google Drive…\")\n",
        "        drive.mount(DRIVE_MOUNT_POINT, force_remount=True)\n",
        "    else:\n",
        "        print(\"Google Drive already mounted.\")\n",
        "\n",
        "# ─── FEATURE COMPUTATION ────────────────────────────────────────────────────────\n",
        "def compute_spatial_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    df['center_x']         = df['x_min'] + (df['x_max'] - df['x_min']) / 2\n",
        "    df['center_y']         = df['y_min'] + (df['y_max'] - df['y_min']) / 2\n",
        "    df['norm_center_x']    = df['center_x'] / df['image_width_px']\n",
        "    df['norm_center_y']    = df['center_y'] / df['image_height_px']\n",
        "    df['bb_area_px']       = (df['x_max'] - df['x_min']) * (df['y_max'] - df['y_min'])\n",
        "    df['relative_bb_area'] = df['bb_area_px'] / (df['image_width_px'] * df['image_height_px'])\n",
        "    return df\n",
        "\n",
        "# ─── SCORING ────────────────────────────────────────────────────────────────────\n",
        "def category_base_score(cat: str) -> float:\n",
        "    return CATEGORY_BASE.get(cat, DEFAULT_BASE)\n",
        "\n",
        "def centrality_bonus(norm_x: float, norm_y: float) -> float:\n",
        "    dist  = np.hypot(norm_x - 0.5, norm_y - 0.5)\n",
        "    bonus = (1 - dist / HALF_DIAGONAL_DISTANCE) * CENTRALITY_BONUS_MAX\n",
        "    return float(max(0.0, bonus))\n",
        "\n",
        "def prominence_bonus(rel_area: float) -> float:\n",
        "    return float(np.sqrt(rel_area) * PROMINENCE_BONUS_MAX)\n",
        "\n",
        "def compute_interaction_scores(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    raw = []\n",
        "    for _, r in df.iterrows():\n",
        "        # people/human categories get 0\n",
        "        if 'human' in str(r['object_category']):\n",
        "            raw.append(0.0)\n",
        "        else:\n",
        "            base  = category_base_score(r['object_category'])\n",
        "            cent  = centrality_bonus(r['norm_center_x'], r['norm_center_y'])\n",
        "            prom  = prominence_bonus(r['relative_bb_area'])\n",
        "            raw_score = (base + cent + prom) * r['confidence']\n",
        "            raw.append(raw_score)\n",
        "    df['interaction_score_raw'] = raw\n",
        "\n",
        "    # normalize to [0,1]\n",
        "    mn, mx = df['interaction_score_raw'].min(), df['interaction_score_raw'].max()\n",
        "    if mx > mn:\n",
        "        df['interaction_score'] = ((df['interaction_score_raw'] - mn) / (mx - mn) * 0.99 + 0.01).round(4)\n",
        "    else:\n",
        "        df['interaction_score'] = 0.0\n",
        "\n",
        "    # ensure humans stay at 0\n",
        "    human_mask = df['object_category'].str.contains('human', na=False)\n",
        "    df.loc[human_mask, 'interaction_score'] = 0.0\n",
        "\n",
        "    return df\n",
        "\n",
        "# ─── TRACK / ID ASSIGNMENT ──────────────────────────────────────────────────────\n",
        "def assign_ids(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    - frame_id: already present\n",
        "    - object_id: already present\n",
        "    - track_id: mocked as '<frame_id>_<object_name>_<n>' per frame\n",
        "    - segmentation_mask: empty JSON string\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    df['segmentation_mask'] = '[]'\n",
        "    df['machine_id']        = ''  # if you have a MID column, copy it here\n",
        "    df['track_id']          = None\n",
        "\n",
        "    # within each frame and object_name, number them\n",
        "    def make_track(sub):\n",
        "        counts = {}\n",
        "        tracks = []\n",
        "        for obj, oid in zip(sub['object_name'], sub['object_id']):\n",
        "            counts[obj] = counts.get(obj, 0) + 1\n",
        "            tracks.append(f\"{sub.name}_{obj}_{counts[obj]}\")\n",
        "        return tracks\n",
        "\n",
        "    # groupby frame_id\n",
        "    tracks = []\n",
        "    for frame, group in df.groupby('frame_id'):\n",
        "        group = group.copy()\n",
        "        group.name = frame\n",
        "        tracks.extend(make_track(group))\n",
        "\n",
        "    df['track_id'] = tracks\n",
        "    return df\n",
        "\n",
        "# ─── MAIN ───────────────────────────────────────────────────────────────────────\n",
        "def main():\n",
        "    mount_drive()\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(INPUT_CSV_PATH)\n",
        "        print(f\"Loaded {len(df)} rows from {INPUT_CSV_PATH.name}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Missing input: {INPUT_CSV_PATH}\")\n",
        "        return\n",
        "\n",
        "    # compute features + scores + IDs\n",
        "    df = compute_spatial_features(df)\n",
        "    df = compute_interaction_scores(df)\n",
        "    df = assign_ids(df)\n",
        "\n",
        "    # drop helper columns\n",
        "    drop_cols = [\n",
        "        'center_x','center_y',\n",
        "        'norm_center_x','norm_center_y',\n",
        "        'bb_area_px','relative_bb_area',\n",
        "        'interaction_score_raw'\n",
        "    ]\n",
        "    df.drop(columns=drop_cols, inplace=True)\n",
        "\n",
        "    # enforce final schema\n",
        "    schema = [\n",
        "        'frame_id','track_id','object_id','timestamp_sec',\n",
        "        'image_width_px','image_height_px','machine_id',\n",
        "        'object_name','object_category',\n",
        "        'x_min','y_min','x_max','y_max',\n",
        "        'segmentation_mask','confidence','interaction_score'\n",
        "    ]\n",
        "    df = df[schema]\n",
        "\n",
        "    df.to_csv(OUTPUT_CSV_PATH, index=False)\n",
        "    print(f\"Saved {len(df)} scored annotations to {OUTPUT_CSV_PATH}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66DB35jiWG_l",
        "outputId": "bde3921e-f540-4e87-a1e1-721536646043"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive…\n",
            "Mounted at /content/drive\n",
            "Loaded 2176 rows from temp_annotations.csv\n",
            "Saved 2176 scored annotations to /content/drive/MyDrive/FreeFuse_Project/Extracted_Stills/final_annotations.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5) Generate Week 4 Deliverable"
      ],
      "metadata": {
        "id": "f3lcq1CUXuuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "# ─── USER CONFIGURATION ─────────────────────────────────────────────────────────\n",
        "INPUT_CSV_PATH     = Path(\"/content/drive/MyDrive/FreeFuse_Project/Extracted_Stills/final_annotations.csv\")\n",
        "OUTPUT_MATRIX_PNG  = Path(\"/content/drive/MyDrive/FreeFuse_Project/insight_prioritization_matrix.png\")\n",
        "# ────────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "def mount_drive(mount_point: str = \"/content/drive\") -> None:\n",
        "    \"\"\"Mount Google Drive in Colab if not already mounted.\"\"\"\n",
        "    mount_point = Path(mount_point)\n",
        "    if not mount_point.is_mount():\n",
        "        print(\"Mounting Google Drive…\")\n",
        "        drive.mount(str(mount_point), force_remount=True)\n",
        "    else:\n",
        "        print(\"Google Drive already mounted.\")\n",
        "\n",
        "def validate_dataframe(df: pd.DataFrame) -> None:\n",
        "    \"\"\"Ensure required columns exist in the DataFrame.\"\"\"\n",
        "    required = {\n",
        "        \"object_id\", \"object_category\", \"interaction_score\"\n",
        "    }\n",
        "    missing = required - set(df.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing required columns in input CSV: {missing}\")\n",
        "\n",
        "def prepare_plot_data(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Aggregates by object_category to compute:\n",
        "      - frequency (count of detections)\n",
        "      - mean_interaction_score\n",
        "      - log10 of frequency for plotting\n",
        "    Filters out any 'human' categories.\n",
        "    \"\"\"\n",
        "    # Filter out human-related categories\n",
        "    mask = ~df[\"object_category\"].str.contains(\"human\", na=False)\n",
        "    df_filtered = df.loc[mask, :]\n",
        "\n",
        "    agg = (\n",
        "        df_filtered\n",
        "        .groupby(\"object_category\", as_index=False)\n",
        "        .agg(\n",
        "            frequency=(\"object_id\", \"nunique\"),\n",
        "            mean_interaction_score=(\"interaction_score\", \"mean\")\n",
        "        )\n",
        "    )\n",
        "    agg[\"log_frequency\"] = np.log10(agg[\"frequency\"].replace(0, np.nan)).fillna(0)\n",
        "    return agg\n",
        "\n",
        "def generate_matrix_plot(plot_df: pd.DataFrame, output_path: Path) -> None:\n",
        "    \"\"\"\n",
        "    Creates and saves a 2×2 prioritization matrix:\n",
        "      - x-axis: log10(frequency)\n",
        "      - y-axis: mean interaction score\n",
        "      - bubble size: frequency\n",
        "      - quadrants defined by median splits\n",
        "    \"\"\"\n",
        "    if plot_df.empty:\n",
        "        print(\"No data to plot.\")\n",
        "        return\n",
        "\n",
        "    # Set dark background and figure size\n",
        "    plt.style.use(\"dark_background\")\n",
        "    fig, ax = plt.subplots(figsize=(14, 10))\n",
        "\n",
        "    # Scatter\n",
        "    sns.scatterplot(\n",
        "        data=plot_df,\n",
        "        x=\"log_frequency\",\n",
        "        y=\"mean_interaction_score\",\n",
        "        size=\"frequency\",\n",
        "        sizes=(100, 1500),\n",
        "        hue=\"object_category\",\n",
        "        alpha=0.8,\n",
        "        palette=\"tab10\",\n",
        "        ax=ax,\n",
        "        legend=\"brief\"\n",
        "    )\n",
        "\n",
        "    # Annotations\n",
        "    for _, row in plot_df.iterrows():\n",
        "        ax.text(\n",
        "            row.log_frequency,\n",
        "            row.mean_interaction_score + 0.02,\n",
        "            row.object_category,\n",
        "            ha=\"center\",\n",
        "            va=\"bottom\",\n",
        "            fontsize=9,\n",
        "            color=\"white\"\n",
        "        )\n",
        "\n",
        "    # Quadrant lines\n",
        "    x_med = plot_df.log_frequency.median()\n",
        "    y_med = plot_df.mean_interaction_score.median()\n",
        "    ax.axvline(x_med, color=\"red\", ls=\"--\", lw=1)\n",
        "    ax.axhline(y_med, color=\"red\", ls=\"--\", lw=1)\n",
        "\n",
        "    # Quadrant labels\n",
        "    x0, x1 = ax.get_xlim()\n",
        "    y0, y1 = ax.get_ylim()\n",
        "    ax.text(x1, y1, \"Prioritize\", ha=\"right\", va=\"top\", color=\"lightgreen\", weight=\"bold\")\n",
        "    ax.text(x0, y1, \"Explore\",    ha=\"left\",  va=\"top\", color=\"skyblue\",   weight=\"bold\")\n",
        "    ax.text(x1, y0, \"Automate\",   ha=\"right\", va=\"bottom\", color=\"orange\",   weight=\"bold\")\n",
        "    ax.text(x0, y0, \"Deprioritize\", ha=\"left\", va=\"bottom\", color=\"gray\",     weight=\"bold\")\n",
        "\n",
        "    # Labels & legend\n",
        "    ax.set_title(\"Object Prioritization Matrix\", fontsize=18, pad=16)\n",
        "    ax.set_xlabel(\"Log₁₀(Object Frequency)\", fontsize=14)\n",
        "    ax.set_ylabel(\"Mean Interaction Score\",   fontsize=14)\n",
        "    ax.legend(title=\"Category\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save\n",
        "    fig.savefig(str(output_path), dpi=300)\n",
        "    plt.close(fig)\n",
        "    print(f\"Matrix plot saved to {output_path}\")\n",
        "\n",
        "def main():\n",
        "    mount_drive()\n",
        "    try:\n",
        "        df = pd.read_csv(INPUT_CSV_PATH)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Input CSV not found at {INPUT_CSV_PATH}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        validate_dataframe(df)\n",
        "    except ValueError as err:\n",
        "        print(f\"Validation error: {err}\")\n",
        "        return\n",
        "\n",
        "    plot_df = prepare_plot_data(df)\n",
        "    print(f\"Prepared data for {len(plot_df)} categories.\")\n",
        "    generate_matrix_plot(plot_df, OUTPUT_MATRIX_PNG)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbIz-77OX1dC",
        "outputId": "60912691-3d09-40af-a754-5df441b133cb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Drive already mounted.\n",
            "Prepared data for 16 categories.\n",
            "Matrix plot saved to /content/drive/MyDrive/FreeFuse_Project/insight_prioritization_matrix.png\n"
          ]
        }
      ]
    }
  ]
}