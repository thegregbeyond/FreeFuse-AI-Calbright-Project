{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOK8z9vM5aVNwErf9zoo9xC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thegregbeyond/FreeFuse-AI-Calbright-Project/blob/main/Image_Extraction%2C_Object_Detection%2C_%26_Labeling_RoboFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Extract Video Stills"
      ],
      "metadata": {
        "id": "5FmghcqzHyY7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8it6gaWVGPL"
      },
      "outputs": [],
      "source": [
        "# Extract Video Stills\n",
        "\n",
        "# === Import Libraries ===\n",
        "\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "\n",
        "# === Configuration ===\n",
        "INPUT_DIR = Path('/content/drive/MyDrive/FreeFuse_Project/Source_Videos/Free-Use Videos from Pexels')\n",
        "OUTPUT_DIR = Path('/content/drive/MyDrive/FreeFuse_Project/Extracted_Stills')\n",
        "CAPTURE_INTERVAL_S = 3      # seconds between captures\n",
        "START_TIME_S = 1            # skip first N seconds of each video\n",
        "VIDEO_EXTS = {'.mp4', '.mov', '.avi'}\n",
        "\n",
        "# === Functions ===\n",
        "def mount_drive():\n",
        "    \"\"\"Mount Google Drive to /content/drive\"\"\"\n",
        "    print(\"Mounting Google Drive...\")\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    print(\"Drive mounted.\")\n",
        "\n",
        "def extract_stills(input_dir: Path, output_dir: Path, interval_s: float, start_s: float):\n",
        "    \"\"\"\n",
        "    Extract still frames from all videos in input_dir at every interval_s seconds,\n",
        "    starting after start_s seconds, saving to output_dir.\n",
        "    \"\"\"\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    video_files = [f for f in input_dir.iterdir() if f.suffix.lower() in VIDEO_EXTS]\n",
        "\n",
        "    if not video_files:\n",
        "        print(f\"No videos found in {input_dir}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(video_files)} videos in {input_dir}\\n\")\n",
        "    for idx, video_file in enumerate(video_files, start=1):\n",
        "        print(f\"[{idx}/{len(video_files)}] Processing '{video_file.name}'\")\n",
        "        cap = cv2.VideoCapture(str(video_file))\n",
        "        if not cap.isOpened():\n",
        "            print(f\"  ✗ Could not open {video_file.name}, skipping.\")\n",
        "            continue\n",
        "\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
        "        start_frame = int(start_s * fps)\n",
        "        if start_frame > 0:\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
        "            print(f\"  → Skipped first {start_s}s ({start_frame} frames)\")\n",
        "\n",
        "        next_capture = start_s\n",
        "        saved_count = 0\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            current_s = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0\n",
        "            if current_s >= next_capture:\n",
        "                mm = int(current_s // 60)\n",
        "                ss = int(current_s % 60)\n",
        "                timestamp = f\"{mm:02d}{ss:02d}\"\n",
        "                out_name = f\"{video_file.stem}_{timestamp}.jpg\"\n",
        "                out_path = output_dir / out_name\n",
        "                cv2.imwrite(str(out_path), frame)\n",
        "                print(f\"  ✔ Saved frame '{out_name}'\")\n",
        "                saved_count += 1\n",
        "                next_capture += interval_s\n",
        "\n",
        "        cap.release()\n",
        "        print(f\"  Completed '{video_file.name}', saved {saved_count} frames.\\n\")\n",
        "\n",
        "    print(\"All videos processed.\")\n",
        "\n",
        "# === Main Execution ===\n",
        "mount_drive()\n",
        "extract_stills(INPUT_DIR, OUTPUT_DIR, CAPTURE_INTERVAL_S, START_TIME_S)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Object Detection"
      ],
      "metadata": {
        "id": "a_9DCsIuJdxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Object Annotations from RoboFlow:\n",
        "'''\n",
        "IMPORTANT:\n",
        "This project assumes that the API Key is stored in\n",
        "Colab Secrets under the name 'ROBOFLOW_API_KEY'. To\n",
        "configure, click the key icon in Colab, and add the\n",
        "name and value.\n",
        "'''\n",
        "\n",
        "# Install RoboFlow SDK\n",
        "!pip install inference-sdk -q\n",
        "\n",
        "# Imports & Configurable Parameters\n",
        "import os\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from inference_sdk import InferenceHTTPClient\n",
        "from google.colab import drive, userdata\n",
        "\n",
        "# === Configurable Parameters ===\n",
        "stills_folder_path   = '/content/drive/MyDrive/FreeFuse_Project/Extracted_Stills'\n",
        "output_csv_path      = '/content/drive/MyDrive/FreeFuse_Project/Extracted_Stills/draft_annotations.csv'\n",
        "max_objects_per_image = 10\n",
        "confidence_threshold  = 0.4\n",
        "\n",
        "# RoboFlow workflow settings\n",
        "workflow_id          = 'freefusetestwf'       # <-- set your workflow ID here\n",
        "workspace_name       = 'student-workspace'    # <-- set your workspace name here\n",
        "# ===============================\n",
        "\n",
        "# Mount Google Drive\n",
        "print(\"Connecting to Google Drive...\")\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "print(\"Google Drive connected.\")\n",
        "\n",
        "# Retrieve API key\n",
        "try:\n",
        "    ROBOFLOW_API_KEY = userdata.get('ROBOFLOW_API_KEY')\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"ERROR: Secret 'ROBOFLOW_API_KEY' not found.\")\n",
        "    ROBOFLOW_API_KEY = None\n",
        "\n",
        "# Initialize RoboFlow client\n",
        "if not ROBOFLOW_API_KEY:\n",
        "    raise ValueError(\"RoboFlow API key is missing. Aborting.\")\n",
        "client = InferenceHTTPClient(\n",
        "    api_url=\"https://serverless.roboflow.com\",\n",
        "    api_key=ROBOFLOW_API_KEY\n",
        ")\n",
        "print(\"Roboflow client initialized.\")\n",
        "\n",
        "# Prepare to collect annotations\n",
        "all_annotations = []\n",
        "image_files = []\n",
        "try:\n",
        "    image_files = [\n",
        "        f for f in os.listdir(stills_folder_path)\n",
        "        if f.lower().endswith(('.jpg','.jpeg','.png'))\n",
        "    ]\n",
        "except FileNotFoundError:\n",
        "    raise FileNotFoundError(f\"Input folder not found: {stills_folder_path}\")\n",
        "\n",
        "if not image_files:\n",
        "    print(\"No images found. Exiting.\")\n",
        "else:\n",
        "    print(f\"Processing {len(image_files)} images...\")\n",
        "\n",
        "    for idx, img_name in enumerate(image_files, start=1):\n",
        "        print(f\"[{idx}/{len(image_files)}] {img_name}\")\n",
        "        img_path = os.path.join(stills_folder_path, img_name)\n",
        "        frame_id = os.path.splitext(img_name)[0]\n",
        "\n",
        "        try:\n",
        "            # Call the workflow\n",
        "            result = client.run_workflow(\n",
        "                workspace_name=workspace_name,\n",
        "                workflow_id=workflow_id,\n",
        "                images={\"image\": img_path},\n",
        "                use_cache=True\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"  Error invoking RoboFlow on {img_name}: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Parse response\n",
        "        if not (isinstance(result, list) and result and 'output' in result[0]):\n",
        "            print(f\"  Unexpected response for {img_name}\")\n",
        "            continue\n",
        "        preds = result[0]['output'].get('predictions', {}).get('predictions', [])\n",
        "\n",
        "        # Sort and filter\n",
        "        preds.sort(key=lambda p: p.get('confidence', 0), reverse=True)\n",
        "        count = 0\n",
        "\n",
        "        # Load dimensions once\n",
        "        from PIL import Image\n",
        "        im = Image.open(img_path)\n",
        "        w, h = im.size\n",
        "\n",
        "        for p in preds:\n",
        "            if count >= max_objects_per_image:\n",
        "                break\n",
        "            conf = p.get('confidence', 0)\n",
        "            if conf < confidence_threshold:\n",
        "                continue\n",
        "\n",
        "            # Convert center/wh to pixel bounds\n",
        "            xc, yc, bw, bh = p.get('x',0), p.get('y',0), p.get('width',0), p.get('height',0)\n",
        "            x_min = int(xc - bw/2)\n",
        "            y_min = int(yc - bh/2)\n",
        "            x_max = int(xc + bw/2)\n",
        "            y_max = int(yc + bh/2)\n",
        "            # clamp to image\n",
        "            x_min, y_min = max(0,x_min), max(0,y_min)\n",
        "            x_max, y_max = min(w, x_max), min(h, y_max)\n",
        "            area = (x_max - x_min) * (y_max - y_min)\n",
        "\n",
        "            # Build an object_id\n",
        "            object_id = f\"{frame_id}_obj{count+1}\"\n",
        "\n",
        "            all_annotations.append({\n",
        "                'frame_id': frame_id,\n",
        "                'image_file_name': img_name,\n",
        "                'timestamp_sec': int(float(frame_id.split('_')[-1])),  # adjust if your naming differs\n",
        "                'image_width_px': w,\n",
        "                'image_height_px': h,\n",
        "                'object_id': object_id,\n",
        "                'object_name': p.get('class','unknown').lower().replace(' ','_'),\n",
        "                'object_category': 'N/A',\n",
        "                'x_min': x_min,\n",
        "                'y_min': y_min,\n",
        "                'x_max': x_max,\n",
        "                'y_max': y_max,\n",
        "                'bb_area_px': area,\n",
        "                'confidence': round(conf,4),\n",
        "                'review_status': 'pending',\n",
        "                'reviewer_notes': ''\n",
        "            })\n",
        "            count += 1\n",
        "\n",
        "# Export to CSV\n",
        "if all_annotations:\n",
        "    df = pd.DataFrame(all_annotations, columns=[\n",
        "        'frame_id','image_file_name','timestamp_sec',\n",
        "        'image_width_px','image_height_px','object_id',\n",
        "        'object_name','object_category','x_min','y_min','x_max','y_max',\n",
        "        'bb_area_px','confidence','review_status','reviewer_notes'\n",
        "    ])\n",
        "    df.to_csv(output_csv_path, index=False)\n",
        "    print(f\"Saved {len(df)} rows to {output_csv_path}\")\n",
        "else:\n",
        "    print(\"No annotations collected.\")"
      ],
      "metadata": {
        "id": "o9R7_AGxCOx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Label Stills"
      ],
      "metadata": {
        "id": "SG4UZ4sDQ8hJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "\n",
        "# === Configuration ===\n",
        "STILLS_DIR = Path('/content/drive/MyDrive/FreeFuse_Project/Extracted_Stills')\n",
        "ANNOTATIONS_CSV = STILLS_DIR / 'draft_annotations.csv'\n",
        "OUTPUT_DIR = Path('/content/drive/MyDrive/FreeFuse_Project/Labeled_Stills')\n",
        "\n",
        "BOX_COLOR = (0, 255, 0)       # BGR\n",
        "TEXT_COLOR = (255, 255, 255)  # BGR\n",
        "BOX_THICKNESS = 2\n",
        "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
        "FONT_SCALE = 0.6\n",
        "LINE_TYPE = cv2.LINE_AA\n",
        "\n",
        "# === Helper Functions ===\n",
        "def mount_drive():\n",
        "    \"\"\"Mount Google Drive.\"\"\"\n",
        "    print(\"Mounting Google Drive...\")\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    print(\"Drive mounted.\")\n",
        "\n",
        "def load_annotations(csv_path: Path) -> pd.DataFrame:\n",
        "    \"\"\"Load and validate annotation CSV.\"\"\"\n",
        "    if not csv_path.exists():\n",
        "        raise FileNotFoundError(f\"Annotation file not found: {csv_path}\")\n",
        "    df = pd.read_csv(csv_path)\n",
        "    required_cols = {\n",
        "        'frame_id','image_file_name','timestamp_sec',\n",
        "        'image_width_px','image_height_px','object_id',\n",
        "        'object_name','object_category','x_min','y_min','x_max','y_max',\n",
        "        'bb_area_px','confidence','review_status','reviewer_notes'\n",
        "    }\n",
        "    missing = required_cols - set(df.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing columns in CSV: {missing}\")\n",
        "    return df\n",
        "\n",
        "def annotate_and_save(df: pd.DataFrame, stills_dir: Path, output_dir: Path):\n",
        "    \"\"\"Draw bounding boxes on images and save annotated copies.\"\"\"\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    grouped = df.groupby('image_file_name')\n",
        "    print(f\"Found annotations for {len(grouped)} images.\")\n",
        "    for idx, (img_name, group) in enumerate(grouped, start=1):\n",
        "        print(f\"[{idx}/{len(grouped)}] Annotating {img_name}\")\n",
        "        img_path = stills_dir / img_name\n",
        "        if not img_path.exists():\n",
        "            print(f\"  Image not found: {img_path}\")\n",
        "            continue\n",
        "        image = cv2.imread(str(img_path))\n",
        "        if image is None:\n",
        "            print(f\"  Failed to load image: {img_path}\")\n",
        "            continue\n",
        "\n",
        "        # Draw each annotation\n",
        "        for _, row in group.iterrows():\n",
        "            x_min = int(row['x_min'])\n",
        "            y_min = int(row['y_min'])\n",
        "            x_max = int(row['x_max'])\n",
        "            y_max = int(row['y_max'])\n",
        "            label = row['object_name']\n",
        "            conf = row['confidence']\n",
        "            # Draw bounding box\n",
        "            cv2.rectangle(image, (x_min, y_min), (x_max, y_max), BOX_COLOR, BOX_THICKNESS)\n",
        "            # Text background\n",
        "            text = f\"{label}: {conf:.2f}\"\n",
        "            (w, h), _ = cv2.getTextSize(text, FONT, FONT_SCALE, 1)\n",
        "            cv2.rectangle(image, (x_min, y_min - h - 4), (x_min + w, y_min), BOX_COLOR, -1)\n",
        "            # Text overlay\n",
        "            cv2.putText(image, text, (x_min, y_min - 2), FONT, FONT_SCALE, TEXT_COLOR, 1, LINE_TYPE)\n",
        "\n",
        "        # Save annotated image\n",
        "        out_name = img_path.stem + '_annotated.jpg'\n",
        "        out_path = output_dir / out_name\n",
        "        cv2.imwrite(str(out_path), image)\n",
        "    print(\"Annotation of images complete.\")\n",
        "\n",
        "# === Main Execution ===\n",
        "mount_drive()\n",
        "try:\n",
        "    annotations_df = load_annotations(ANNOTATIONS_CSV)\n",
        "    annotate_and_save(annotations_df, STILLS_DIR, OUTPUT_DIR)\n",
        "except Exception as e:\n",
        "    print(f\"ERROR: {e}\")\n"
      ],
      "metadata": {
        "id": "WmC0zzZaPf1p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}