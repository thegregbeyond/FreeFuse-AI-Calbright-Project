{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMIREKXwboWgeSgj/GzsKR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thegregbeyond/FreeFuse-AI-Calbright-Project/blob/main/Video_Face_Blurring_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install libs\n",
        "!pip install insightface onnxruntime-gpu -q\n",
        "\n",
        "# Import libs\n",
        "import os\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import numpy as np\n",
        "from insightface.app import FaceAnalysis\n",
        "\n",
        "# --- User Params ---\n",
        "\n",
        "INPUT_FOLDER        = \"/content/drive/MyDrive/FreeFuse_Project/Videos/Input\"\n",
        "OUTPUT_FOLDER       = \"/content/drive/MyDrive/FreeFuse_Project/Videos/Blurred\"\n",
        "BLUR_INTENSITY      = 51        # must be odd\n",
        "FACE_CONF_THRESHOLD = 0.3       # detection score threshold (0–1)\n",
        "\n",
        "# --- End Parameters ---\n",
        "\n",
        "# Initialize face detector\n",
        "print(\"Loading RetinaFace via FaceAnalysis…\")\n",
        "fa = FaceAnalysis(allowed_modules=[\"detection\"], providers=[\"CPUExecutionProvider\"])\n",
        "fa.prepare(ctx_id=0, det_size=(640, 640))\n",
        "\n",
        "def blur_roi(frame, x1, y1, x2, y2, ksize):\n",
        "    roi = frame[y1:y2, x1:x2]\n",
        "    if roi.size:\n",
        "        frame[y1:y2, x1:x2] = cv2.GaussianBlur(roi, (ksize, ksize), 0)\n",
        "\n",
        "# Iterate over each video in the input folder\n",
        "for vid_path in Path(INPUT_FOLDER).glob(\"*.*\"):\n",
        "    if vid_path.suffix.lower() not in [\".mp4\", \".mov\", \".avi\", \".mkv\"]:\n",
        "        continue\n",
        "\n",
        "    cap = cv2.VideoCapture(str(vid_path))\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Couldn’t open {vid_path.name}, skipping.\")\n",
        "        continue\n",
        "\n",
        "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    out_path = Path(OUTPUT_FOLDER) / f\"{vid_path.stem}_blurred{vid_path.suffix}\"\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "    writer = cv2.VideoWriter(str(out_path), fourcc, fps, (w, h))\n",
        "\n",
        "    print(f\"\\nProcessing {vid_path.name} → {out_path.name}\")\n",
        "    frame_idx = 0\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # detect faces\n",
        "        faces = fa.get(frame)\n",
        "        for face in faces:\n",
        "            score = face.det_score\n",
        "            if score < FACE_CONF_THRESHOLD:\n",
        "                continue\n",
        "            x1, y1, x2, y2 = map(int, face.bbox)\n",
        "            blur_roi(frame, x1, y1, x2, y2, BLUR_INTENSITY)\n",
        "\n",
        "        writer.write(frame)\n",
        "        frame_idx += 1\n",
        "        if frame_idx % 100 == 0:\n",
        "            print(f\"   processed {frame_idx}/{total} frames…\")\n",
        "\n",
        "    cap.release()\n",
        "    writer.release()\n",
        "    print(f\"Finished {out_path.name}\")\n",
        "\n",
        "print(\"\\nAll videos processed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIdbccQRfSgg",
        "outputId": "cc8d21e7-0e4c-406e-b87c-1f65a37625ea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading RetinaFace via FaceAnalysis…\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "model ignore: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "model ignore: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "model ignore: /root/.insightface/models/buffalo_l/genderage.onnx genderage\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "model ignore: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition\n",
            "set det-size: (640, 640)\n",
            "\n",
            "All videos processed!\n"
          ]
        }
      ]
    }
  ]
}